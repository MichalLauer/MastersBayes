@article{Abanto-ValleEtAl2011_StochasticVolatilityMean,
  title = {Stochastic Volatility in Mean Models with Scale Mixtures of Normal Distributions and Correlated Errors: {{A Bayesian}} Approach},
  author = {Abanto-Valle, C.A. and Migon, H.S. and Lachos, V.H.},
  date = {2011},
  journaltitle = {Journal of Statistical Planning and Inference},
  volume = {141},
  number = {5},
  pages = {1875--1887},
  issn = {0378-3758},
  doi = {10.1016/j.jspi.2010.11.039},
  url = {https://www.sciencedirect.com/science/article/pii/S0378375810005392},
  abstract = {A stochastic volatility in mean model with correlated errors using the symmetrical class of scale mixtures of normal distributions is introduced in this article. The scale mixture of normal distributions is an attractive class of symmetric distributions that includes the normal, Student-t, slash and contaminated normal distributions as special cases, providing a robust alternative to estimation in stochastic volatility in mean models in the absence of normality. Using a Bayesian paradigm, an efficient method based on Markov chain Monte Carlo (MCMC) is developed for parameter estimation. The methods developed are applied to analyze daily stock return data from the São Paulo Stock, Mercantile \& Futures Exchange index (IBOVESPA). The Bayesian predictive information criteria (BPIC) and the logarithm of the marginal likelihood are used as model selection criteria. The results reveal that the stochastic volatility in mean model with correlated errors and slash distribution provides a significant improvement in model fit for the IBOVESPA data over the usual normal model.},
  keywords = {Feedback and leverage effect,literatura,Markov chain Monte Carlo,Non-Gaussian and nonlinear state-space models,Scale mixture of normal distributions,Stochastic volatility in mean}
}

@article{AL-Najjar2016_ModellingEstimationVolatility,
  title = {Modelling and {{Estimation}} of {{Volatility Using ARCH}}/{{GARCH Models}} in {{Jordan}}’s {{Stock Market}}},
  author = {AL-Najjar, Dana Mohammad},
  date = {2016-05-06},
  journaltitle = {Asian Journal of Finance \& Accounting},
  shortjournal = {AJFA},
  volume = {8},
  number = {1},
  pages = {152},
  issn = {1946-052X},
  doi = {10.5296/ajfa.v8i1.9129},
  url = {http://www.macrothink.org/journal/index.php/ajfa/article/view/9129},
  urldate = {2025-04-05},
  abstract = {{$<$}p{$>$}Financials have been concerned constantly with factors that have impact on both taking and assessing various financial decisions in firms. Hence modelling volatility in financial markets is one of the factors that have direct role and effect on pricing, risk and portfolio management. Therefore, this study aims to examine the volatility characteristics on Jordan’s capital market that include; clustering volatility, leptokurtosis, and leverage effect. This objective can be accomplished by selecting symmetric and asymmetric models from GARCH family models. This study applies; ARCH, GARCH, and EGARCH to investigate the behavior of stock return volatility for Amman Stock Exchange (ASE) covering the period from Jan. 1 2005 through Dec.31 2014. The main findings suggest that the symmetric ARCH /GARCH models can capture characteristics of ASE, and provide more evidence for both volatility clustering and leptokurtic, whereas EGARCH output reveals no support for the existence of leverage effect in the stock returns at Amman Stock Exchange.{$<$}/p{$>$}},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\YE9E22T5\AL-Najjar - 2016 - Modelling and Estimation of Volatility Using ARCHGARCH Models in Jordan’s Stock Market.pdf}
}

@article{AlimuDayimu2024BayesianHM,
  title = {Bayesian Hierarchical Models of Basket Trials in the Context of Economic Evaluation},
  author = {Dayimu, PhD Alimu and Demiris, PhD Nikos and Lee, MA Karen and Cromwell, PhD Ian and family=Heath, given=Mmath Anna, given-i={{Mm}}A and Pechlivanoglou, PhD Petros},
  date = {2024},
  journaltitle = {Canadian Journal of Health Technologies},
  url = {https://api.semanticscholar.org/CorpusID:270207604},
  keywords = {literatura}
}

@article{AndradeFernandez2016_InterpretationConfidenceInterval,
  title = {Interpretation of {{Confidence Interval Facing}} the {{Conflict}}},
  author = {Andrade, Luisa and Fernández, Felipe},
  date = {2016-12},
  journaltitle = {Universal Journal of Educational Research},
  shortjournal = {ujer},
  volume = {4},
  number = {12},
  pages = {2687--2700},
  issn = {2332-3205, 2332-3213},
  doi = {10.13189/ujer.2016.041201},
  url = {http://www.hrpub.org/journals/article_info.php?aid=5357},
  urldate = {2025-04-13},
  langid = {english},
  keywords = {literatura}
}

@dataset{Ardia2008_BayesGARCHBayesianEstimation,
  title = {{{bayesGARCH}}: {{Bayesian Estimation}} of the {{GARCH}}(1,1) {{Model}} with {{Student-t Innovations}}},
  shorttitle = {{{bayesGARCH}}},
  author = {Ardia, David},
  date = {2008-06-03},
  pages = {2.1.10},
  publisher = {Comprehensive R Archive Network},
  doi = {10.32614/CRAN.package.bayesGARCH},
  url = {https://CRAN.R-project.org/package=bayesGARCH},
  urldate = {2025-04-21},
  abstract = {Provides the bayesGARCH() function which performs the Bayesian estimation of the GARCH(1,1) model with Student's t innovations as described in Ardia (2008) {$<$}doi:10.1007/978-3-540-78657-3{$>$}.},
  langid = {english},
  keywords = {balicek}
}

@article{AriPapadopoulos2016_BayesianEstimationParameters,
  title = {Bayesian Estimation of the Parameters of the {{ARCH}} Model with {{Normal Innovations}} Using {{Lindley}}’s Approximation},
  author = {Ari, Yakup and Papadopoulos, Alex},
  date = {2016-12-10},
  journaltitle = {Economic computation and economic cybernetics studies and research / Academy of Economic Studies},
  shortjournal = {Economic computation and economic cybernetics studies and research / Academy of Economic Studies},
  volume = {3},
  pages = {251},
  abstract = {Autoregressive conditionally heteroscedastic (ARCH) models are used to analyze empirical financial data and capture various stylized facts in financial econometrics. The procedure that is most commonly used for estimating the unknown parameters of an ARCH model is the maximum likelihood estimation (MLE). In this study, it is assumed that the parameters of the ARCH model are random variables having known prior probability density functions, and therefore they will be estimated using Bayesian methods. The Bayesian estimators are not in a closed form, and thus Lindley's approximation will be used to estimate them. The Bayesian estimators are derived under squared error loss (SEL) and linear exponential (LINEX) loss functions. An example is given in order to illustrate the findings and furthermore, Monte Carlo simulations are performed in order to compare the ML estimates to the Bayesian ones. Finally, conclusions on the findings are given.},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\X6GRRA6Z\Ari a Papadopoulos - 2016 - Bayesian estimation of the parameters of the ARCH model with Normal Innovations using Lindley’s appr.pdf}
}

@article{Ashby2006_BayesianStatisticsMedicine,
  title = {Bayesian Statistics in Medicine: A 25 Year Review: {{BAYESIAN STATISTICS IN MEDICINE}}},
  shorttitle = {Bayesian Statistics in Medicine},
  author = {Ashby, Deborah},
  date = {2006-11-15},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statist. Med.},
  volume = {25},
  number = {21},
  pages = {3589--3631},
  issn = {02776715},
  doi = {10.1002/sim.2672},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.2672},
  urldate = {2025-04-21},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\DNUURE3E\Ashby - 2006 - Bayesian statistics in medicine a 25 year review BAYESIAN STATISTICS IN MEDICINE.pdf}
}

@article{AusinGaleano2007_BayesianEstimationGaussian,
  title = {Bayesian Estimation of the {{Gaussian}} Mixture {{GARCH}} Model},
  author = {Ausín, María Concepción and Galeano, Pedro},
  date = {2007-02},
  journaltitle = {Computational Statistics \& Data Analysis},
  shortjournal = {Computational Statistics \& Data Analysis},
  volume = {51},
  number = {5},
  pages = {2636--2652},
  issn = {01679473},
  doi = {10.1016/j.csda.2006.01.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947306000119},
  urldate = {2025-04-21},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\8QQEA3F9\Ausín a Galeano - 2007 - Bayesian estimation of the Gaussian mixture GARCH model.pdf}
}

@book{Barber2012_BayesianReasoningMachine,
  title = {Bayesian Reasoning and Machine Learning},
  author = {Barber, David},
  date = {2012},
  publisher = {Cambridge University Press},
  location = {Cambridge ; New York},
  isbn = {978-0-521-51814-7},
  pagetotal = {697},
  keywords = {Bayesian statistical decision theory,COMPUTERS / Computer Vision & Pattern Recognition,literatura,Machine learning}
}

@inproceedings{BarberEtAl2016_LaplaceApproximationHighdimensional,
  title = {Laplace Approximation in High-Dimensional Bayesian Regression},
  booktitle = {Statistical Analysis for High-Dimensional Data},
  author = {Barber, Rina Foygel and Drton, Mathias and Tan, Kean Ming},
  editor = {Frigessi, Arnoldo and Bühlmann, Peter and Glad, Ingrid K. and Langaas, Mette and Richardson, Sylvia and Vannucci, Marina},
  date = {2016},
  pages = {15--36},
  publisher = {Springer International Publishing},
  location = {Cham},
  abstract = {We consider Bayesian variable selection in sparse high-dimensional regression, where the number of covariates p may be large relative to the sample size n, but at most a moderate number q of covariates are active. Specifically, we treat generalized linear models. For a single fixed sparse model with well-behaved prior distribution, classical theory proves that the Laplace approximation to the marginal likelihood of the model is accurate for sufficiently large sample size n. We extend this theory by giving results on uniform accuracy of the Laplace approximation across all models in a high-dimensional scenario in which p and q, and thus also the number of considered models, may increase with n. Moreover, we show how this connection between marginal likelihood and Laplace approximation can be used to obtain consistency results for Bayesian approaches to variable selection in high-dimensional regression.},
  isbn = {978-3-319-27099-9},
  keywords = {literatura}
}

@online{BartosEtAl2024_FairCoinsTend,
  title = {Fair Coins Tend to Land on the Same Side They Started: {{Evidence}} from 350,757 Flips},
  shorttitle = {Fair Coins Tend to Land on the Same Side They Started},
  author = {Bartoš, František and Sarafoglou, Alexandra and Godmann, Henrik R. and Sahrani, Amir and Leunk, David Klein and Gui, Pierre Y. and Voss, David and Ullah, Kaleem and Zoubek, Malte J. and Nippold, Franziska and Aust, Frederik and Vieira, Felipe F. and Islam, Chris-Gabriel and Zoubek, Anton J. and Shabani, Sara and Petter, Jonas and Roos, Ingeborg B. and Finnemann, Adam and Lob, Aaron B. and Hoffstadt, Madlen F. and Nak, Jason and family=Ron, given=Jill, prefix=de, useprefix=false and Derks, Koen and Huth, Karoline and Terpstra, Sjoerd and Bastelica, Thomas and Matetovici, Magda and Ott, Vincent L. and Zetea, Andreea S. and Karnbach, Katharina and Donzallaz, Michelle C. and John, Arne and Moore, Roy M. and Assion, Franziska and family=Bork, given=Riet, prefix=van, useprefix=false and Leidinger, Theresa E. and Zhao, Xiaochang and Motaghi, Adrian Karami and Pan, Ting and Armstrong, Hannah and Peng, Tianqi and Bialas, Mara and Pang, Joyce Y.-C. and Fu, Bohan and Yang, Shujun and Lin, Xiaoyi and Sleiffer, Dana and Bognar, Miklos and Aczel, Balazs and Wagenmakers, Eric-Jan},
  date = {2024-06-02},
  eprint = {2310.04153},
  eprinttype = {arXiv},
  eprintclass = {math},
  url = {http://arxiv.org/abs/2310.04153},
  abstract = {Many people have flipped coins but few have stopped to ponder the statistical and physical intricacies of the process. In a preregistered study we collected \$350\{,\}757\$ coin flips to test the counterintuitive prediction from a physics model of human coin tossing developed by Diaconis, Holmes, and Montgomery (DHM; 2007). The model asserts that when people flip an ordinary coin, it tends to land on the same side it started -- DHM estimated the probability of a same-side outcome to be about 51\%. Our data lend strong support to this precise prediction: the coins landed on the same side more often than not, \$\textbackslash text\{Pr\}(\textbackslash text\{same side\}) = 0.508\$, 95\% credible interval (CI) [\$0.506\$, \$0.509\$], \$\textbackslash text\{BF\}\_\{\textbackslash text\{same-side bias\}\} = 2359\$. Furthermore, the data revealed considerable between-people variation in the degree of this same-side bias. Our data also confirmed the generic prediction that when people flip an ordinary coin -- with the initial side-up randomly determined -- it is equally likely to land heads or tails: \$\textbackslash text\{Pr\}(\textbackslash text\{heads\}) = 0.500\$, 95\% CI [\$0.498\$, \$0.502\$], \$\textbackslash text\{BF\}\_\{\textbackslash text\{heads-tails bias\}\} = 0.182\$. Furthermore, this lack of heads-tails bias does not appear to vary across coins. Additional exploratory analyses revealed that the within-people same-side bias decreased as more coins were flipped, an effect that is consistent with the possibility that practice makes people flip coins in a less wobbly fashion. Our data therefore provide strong evidence that when some (but not all) people flip a fair coin, it tends to land on the same side it started. Our data provide compelling statistical support for the DHM physics model of coin tossing.},
  pubstate = {prepublished},
  keywords = {literatura,Mathematics - History and Overview,Physics - Data Analysis Statistics and Probability,Statistics - Other Statistics},
  file = {C\:\\Users\\Michal\\Zotero\\storage\\D8BS2H95\\Bartoš et al. - 2024 - Fair coins tend to land on the same side they star.pdf;C\:\\Users\\Michal\\Zotero\\storage\\TFVHAQSC\\2310.html}
}

@article{BauwensLubrano1998_BayesianInferenceGARCH,
  title = {Bayesian Inference on {{GARCH}} Models Using the {{Gibbs}} Sampler},
  author = {Bauwens, Luc and Lubrano, Michel},
  date = {1998-06-01},
  journaltitle = {The Econometrics Journal},
  volume = {1},
  number = {1},
  pages = {C23-C46},
  issn = {1368-4221, 1368-423X},
  doi = {10.1111/1368-423X.11003},
  url = {https://academic.oup.com/ectj/article/1/1/C23-C46/5071727},
  urldate = {2025-04-21},
  langid = {english},
  keywords = {literatura}
}

@article{Bollerslev1986_GeneralizedAutoregressiveConditional,
  title = {Generalized Autoregressive Conditional Heteroskedasticity},
  author = {Bollerslev, Tim},
  date = {1986-04},
  journaltitle = {Journal of Econometrics},
  shortjournal = {Journal of Econometrics},
  volume = {31},
  number = {3},
  pages = {307--327},
  issn = {03044076},
  doi = {10.1016/0304-4076(86)90063-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0304407686900631},
  urldate = {2025-04-13},
  langid = {english},
  keywords = {literatura}
}

@article{CampbellEtAl1998_ECONOMETRICSFINANCIALMARKETS,
  title = {{{THE ECONOMETRICS OF FINANCIAL MARKETS}}},
  author = {Campbell, John Y. and Lo, Andrew W. and MacKinlay, A. Craig and Whitelaw, Robert F.},
  date = {1998-12},
  journaltitle = {Macroeconomic Dynamics},
  shortjournal = {Macroecon. Dynam.},
  volume = {2},
  number = {4},
  pages = {559--562},
  issn = {1365-1005, 1469-8056},
  doi = {10.1017/S1365100598009092},
  url = {https://www.cambridge.org/core/product/identifier/S1365100598009092/type/journal_article},
  urldate = {2025-03-26},
  abstract = {This book is an ambitious effort by three well-known and well-respected scholars to fill an acknowledged void in the literature—a text covering the burgeoning  field of empirical finance. As the authors note in the preface, there are several excellent books covering financial theory at a level suitable for a Ph.D. class or as a reference for academics and practitioners, but there is little or nothing similar that covers econometric methods and applications. Perhaps the closest existing text is the recent addition to the Wiley               Series in Financial and Quantitative Analysis               .  written by Cuthbertson (1996). The major difference between the books is that Cuthbertson focuses exclusively on asset pricing in the stock, bond, and foreign exchange markets, whereas Campbell, Lo, and MacKinlay (henceforth CLM) consider empirical applications throughout the field of finance, including corporate finance, derivatives markets, and market microstructure. The level of anticipation preceding publication can be partly measured by the fact that at least three reviews (including this one) have appeared since the book arrived. Moreover, in their reviews, both Harvey (1998) and Tiso (1998) comment on the need for such a text, a sentiment that has been echoed by numerous finance academics.},
  langid = {english},
  keywords = {literatura}
}

@article{CarpenterEtAl2017_StanProbabilisticProgramming,
  title = {Stan : {{A Probabilistic Programming Language}}},
  shorttitle = {Stan},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {76},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  url = {http://www.jstatsoft.org/v76/i01/},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\B83GIHYJ\Carpenter et al. - 2017 - Stan  A Probabilistic Programming Language.pdf}
}

@incollection{Cont2007_VolatilityClusteringFinancial,
  title = {Volatility {{Clustering}} in {{Financial Markets}}: {{Empirical Facts}} and {{Agent-Based Models}}},
  shorttitle = {Volatility {{Clustering}} in {{Financial Markets}}},
  booktitle = {Long {{Memory}} in {{Economics}}},
  author = {Cont, Rama},
  editor = {Teyssière, Gilles and Kirman, Alan P.},
  date = {2007},
  pages = {289--309},
  publisher = {Springer Berlin Heidelberg},
  doi = {10.1007/978-3-540-34625-8_10},
  url = {http://link.springer.com/10.1007/978-3-540-34625-8_10},
  urldate = {2025-03-31},
  isbn = {978-3-540-22694-9},
  langid = {english},
  keywords = {literatura}
}

@article{DepaoliVanDeSchoot2017_ImprovingTransparencyReplication,
  title = {Improving Transparency and Replication in {{Bayesian}} Statistics: {{The WAMBS-Checklist}}.},
  shorttitle = {Improving Transparency and Replication in {{Bayesian}} Statistics},
  author = {Depaoli, Sarah and Van De Schoot, Rens},
  date = {2017-06},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {22},
  number = {2},
  pages = {240--261},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000065},
  url = {https://doi.apa.org/doi/10.1037/met0000065},
  urldate = {2025-04-13},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\XXMNXRLC\Depaoli a Van De Schoot - 2017 - Improving transparency and replication in Bayesian statistics The WAMBS-Checklist..pdf}
}

@article{EngleEtAl1987_EstimatingTimeVarying,
  title = {Estimating Time Varying Risk Premia in the Term Structure: {{The}} Arch-m Model},
  author = {Engle, Robert F. and Lilien, David M. and Robins, Russell P.},
  date = {1987},
  journaltitle = {Econometrica : journal of the Econometric Society},
  shortjournal = {Econometrica},
  volume = {55},
  number = {2},
  eprint = {1913242},
  eprinttype = {jstor},
  pages = {391--407},
  publisher = {[Wiley, Econometric Society]},
  issn = {00129682, 14680262},
  url = {http://www.jstor.org/stable/1913242},
  urldate = {2025-04-30},
  abstract = {The expectation of the excess holding yield on a long bond is postulated to depend upon its conditional variance. Engle's (1982a) ARCH model is extended to allow the conditional variance to be a determinant of the mean and is called ARCH-M. Estimation and inference procedures are proposed and the model is applied to three interest rate data sets. In most cases the ARCH process and the time varying risk premium are highly significant. A collection of LM diagnostic tests reveals the robustness of the model to various specification changes such as alternative volatility or ARCH measures, regime changes, and interest rate formulations. The model explains and interprets the recent econometric failures of the expectations hypothesis of the term structure.},
  keywords = {literatura}
}

@book{FernandezRodriguez2020_ModelingVolatilityReturns,
  title = {Modeling the {{Volatility}} of {{Returns}} on {{Commodities}}: {{An Application}} and {{Empirical Comparison}} of {{GARCH}} and {{SV Models}}},
  shorttitle = {Modeling the {{Volatility}} of {{Returns}} on {{Commodities}}},
  author = {Fernández, Jean and Rodríguez, Gabriel},
  date = {2020},
  series = {Documento de Trabajo},
  publisher = {Pontificia Universidad Católica del Perú},
  doi = {10.18800/2079-8474.0484},
  url = {http://repositorio.pucp.edu.pe/index/handle/123456789/176225},
  urldate = {2025-04-08},
  abstract = {Se utilizan siete modelos GARCH y de volatilidad estocástica (SV) para modelar y comparar empíricamente la volatilidad de los rendimientos de cuatro materias primas: oro, cobre, petróleo y gas natural. Los resultados muestran evidencia de colas gruesas y saltos aleatorios creados por desequilibrios de oferta / demanda, episodios de inestabilidad internacional, tensiones geopolíticas y especulación de mercado, entre otros factores. También encontramos evidencia de un efecto apalancamiento en el petróleo y el cobre, derivado de su dependencia de la actividad económica mundial; y de un efecto apalancamiento inverso en oro y gas natural, consistente con el papel del primero como activo seguro y con la incertidumbre sobre la oferta futura del segundo. Además, en la mayoría de los casos no hay evidencia de un impacto de la volatilidad en la media. Finalmente, encontramos que los modelos de volatilidad de rendimiento con mejor desempeño son GARCH-t para el oro.},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\RBYNAVNX\Fernández a Rodríguez - 2020 - Modeling the Volatility of Returns on Commodities An Application and Empirical Comparison of GARCH.pdf}
}

@article{GefangEtAl2019_VariationalBayesianInference,
  title = {Variational {{Bayesian Inference}} in {{Large Vector Autoregressions}} with {{Hierarchical Shrinkage}}},
  author = {Gefang, Deborah and Koop, Gary and Poon, Aubrey},
  date = {2019},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3321510},
  url = {https://www.ssrn.com/abstract=3321510},
  urldate = {2025-04-21},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\94YD76II\Gefang et al. - 2019 - Variational Bayesian Inference in Large Vector Autoregressions with Hierarchical Shrinkage.pdf}
}

@book{Gelman2014_BayesianDataAnalysis,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew},
  date = {2014},
  series = {Chapman \& {{Hall}}/{{CRC}} Texts in Statistical Science},
  edition = {Third edition},
  publisher = {CRC Press},
  location = {Boca Raton},
  abstract = {"Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"--},
  isbn = {978-1-4398-4095-5},
  pagetotal = {661},
  keywords = {Bayesian statistical decision theory,literatura,MATHEMATICS / Probability & Statistics / General},
  file = {C:\Users\Michal\Zotero\storage\UQD7XY6P\Gelman - 2014 - Bayesian data analysis.pdf}
}

@incollection{GelmanEtAl1996_EfficientMetropolisJumping,
  title = {Efficient {{Metropolis Jumping Rules}}},
  booktitle = {Bayesian {{Statistics}} 5},
  author = {Gelman, A and Roberts, G O and Gilks, W R},
  editor = {Bernardo, J M and Berger, J O and Dawid, A P and Smith, A F M},
  date = {1996-05-09},
  pages = {599--608},
  publisher = {Oxford University PressOxford},
  doi = {10.1093/oso/9780198523567.003.0038},
  url = {https://academic.oup.com/book/54042/chapter/422210114},
  urldate = {2025-04-18},
  abstract = {Abstract             The algorithm of Metropolis et al. (1953) and its generalizations have been increasingly popular in computational physics and, more recently, statistics, for sampling from intractable multivariate distributions. Much recent research has been devoted to increasing the efficiency of simulation algorithms by altering the jumping rules for Metropolis-like algorithms. We study a very specific question: What are the most efficient symmetric jumping kernels for simulating a normal target distribution using the Metropolis algorithmã We provide a general theoretical result as the dimension of a class of canonical problems goes to ∞ and numerical approximations and simulations for low-dimensional Gaussian target distributions that show that the limiting results provide extremely accurate approximations in six and higher dimensions.},
  isbn = {978-0-19-852356-7},
  langid = {english},
  keywords = {literatura}
}

@online{GelmanEtAl2020_BayesianWorkflow,
  title = {Bayesian {{Workflow}}},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and Bürkner, Paul-Christian and Modrák, Martin},
  date = {2020-11-03},
  eprint = {2011.01808},
  eprinttype = {arXiv},
  eprintclass = {stat},
  url = {http://arxiv.org/abs/2011.01808},
  urldate = {2024-09-03},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  pubstate = {prepublished},
  keywords = {literatura,Statistics - Methodology},
  file = {C\:\\Users\\Michal\\Zotero\\storage\\F6I5R5TZ\\Gelman et al. - 2020 - Bayesian Workflow.pdf;C\:\\Users\\Michal\\Zotero\\storage\\WH2K5CX8\\2011.html}
}

@article{GelmanStern2006_DifferenceSignificantNot,
  title = {The {{Difference Between}} “{{Significant}}” and “{{Not Significant}}” Is Not {{Itself Statistically Significant}}},
  author = {Gelman, Andrew and Stern, Hal},
  date = {2006-11},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {60},
  number = {4},
  pages = {328--331},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313006X152649},
  url = {http://www.tandfonline.com/doi/abs/10.1198/000313006X152649},
  urldate = {2024-12-02},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\YXIPUKC6\gelman2006.pdf}
}

@book{GewekeEtAl2013_OxfordHandbookBayesian,
  title = {The {{Oxford}} Handbook of {{Bayesian}} Econometrics},
  editor = {Geweke, John and Koop, Gary and family=Dijk, given=Herman K., prefix=van, useprefix=false},
  date = {2013},
  edition = {1. publ. in paperback},
  publisher = {Oxford Univ. Press},
  location = {Oxford},
  isbn = {978-0-19-955908-4},
  langid = {english},
  pagetotal = {558},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\SCLMT2NV\The Oxford Handbook of Bayesian Econometrics (John Geweke (editor), Gary Koop (editor) etc.) (Z-Library).pdf}
}

@article{Griffin2011OnAM,
  title = {On Adaptive {{Metropolis}}–{{Hastings}} Methods},
  author = {Griffin, Jim E. and Walker, Stephen G.},
  date = {2011},
  journaltitle = {Statistics and Computing},
  volume = {23},
  pages = {123--134},
  url = {https://api.semanticscholar.org/CorpusID:14820052},
  keywords = {literatura}
}

@book{Hebak2013_StatistickeMysleniNastroje,
  title = {Statistické myšlení a nástroje analýzy dat},
  author = {Hebák, Petr},
  date = {2013},
  edition = {Vyd. 1},
  publisher = {Informatorium},
  location = {Praha},
  isbn = {978-80-7333-105-4},
  langid = {czech},
  keywords = {literatura},
  annotation = {OCLC: 883371397}
}

@online{HeEtAl2016_ScanOrderGibbs,
  title = {Scan {{Order}} in {{Gibbs Sampling}}: {{Models}} in {{Which}} It {{Matters}} and {{Bounds}} on {{How Much}}},
  shorttitle = {Scan {{Order}} in {{Gibbs Sampling}}},
  author = {He, Bryan and De Sa, Christopher and Mitliagkas, Ioannis and Ré, Christopher},
  date = {2016},
  doi = {10.48550/ARXIV.1606.03432},
  url = {https://arxiv.org/abs/1606.03432},
  urldate = {2025-04-20},
  abstract = {Gibbs sampling is a Markov Chain Monte Carlo sampling technique that iteratively samples variables from their conditional distributions. There are two common scan orders for the variables: random scan and systematic scan. Due to the benefits of locality in hardware, systematic scan is commonly used, even though most statistical guarantees are only for random scan. While it has been conjectured that the mixing times of random scan and systematic scan do not differ by more than a logarithmic factor, we show by counterexample that this is not the case, and we prove that that the mixing times do not differ by more than a polynomial factor under mild conditions. To prove these relative bounds, we introduce a method of augmenting the state space to study systematic scan using conductance.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,literatura,Machine Learning (cs.LG),Machine Learning (stat.ML)}
}

@book{HindlsEtAl2018_StatistikaEkonomii,
  title = {Statistika v ekonomii},
  author = {Hindls, Richard and Arltová, Markéta and Hronová, Stanislava and Malá, Ivana and Marek, Luboš and Pecáková, Iva and Řezanková, Hana},
  date = {2018},
  isbn = {978-80-88260-09-7},
  langid = {czech},
  keywords = {literatura},
  annotation = {OCLC: 1066057734}
}

@online{HoffmanGelman2011_NoUTurnSamplerAdaptively,
  title = {The {{No-U-Turn Sampler}}: {{Adaptively Setting Path Lengths}} in {{Hamiltonian Monte Carlo}}},
  shorttitle = {The {{No-U-Turn Sampler}}},
  author = {Hoffman, Matthew D. and Gelman, Andrew},
  date = {2011},
  doi = {10.48550/ARXIV.1111.4246},
  url = {https://arxiv.org/abs/1111.4246},
  urldate = {2024-11-03},
  abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size ε and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS perform at least as efficiently as and sometimes more efficiently than a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter ε on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all. NUTS is also suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" sampling algorithms.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computation (stat.CO),FOS: Computer and information sciences,literatura,Machine Learning (cs.LG)},
  file = {C:\Users\Michal\Zotero\storage\JUN3F77K\Hoffman and Gelman - 2011 - The No-U-Turn Sampler Adaptively Setting Path Len.pdf}
}

@article{HopkinsEtAl2024_HowWeKnow,
  title = {How {{Do We Know What We Know}}? {{Learning}} from {{Monte Carlo Simulations}}},
  shorttitle = {How {{Do We Know What We Know}}?},
  author = {Hopkins, Vincent and Kagalwala, Ali and Philips, Andrew Q. and Pickup, Mark and Whitten, Guy D.},
  date = {2024-01-01},
  journaltitle = {The Journal of Politics},
  shortjournal = {The Journal of Politics},
  volume = {86},
  number = {1},
  pages = {36--53},
  issn = {0022-3816, 1468-2508},
  doi = {10.1086/726934},
  url = {https://www.journals.uchicago.edu/doi/10.1086/726934},
  urldate = {2025-04-18},
  langid = {english},
  keywords = {literatura}
}

@online{Chudoba2024_DobraCislaAlphabetu,
  title = {Dobrá čísla Alphabetu za 1Q odráží výnosy z Google Search, YouTube a cloudových služeb | Fio banka},
  author = {Chudoba, Marek},
  date = {2024-04-26},
  url = {https://www.fio.cz/zpravodajstvi/zpravy-z-burzy/295450-dobra-cisla-alphabetu-za-1q-odrazi-vynosy-z-google-search-youtube-a-cloudovych-sluzeb},
  urldate = {2025-04-24},
  abstract = {Matka společnosti Google reportovala výnosy za 1Q, které překonaly očekávání. Umělá inteligence podpořila růst cloudového segmentu. Analytici uvítali novou dividendu společnosti a další zpětný odkup ve výši 70 mld. USD dolarů.},
  langid = {czech},
  organization = {Fio},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\AQG5CMN8\295450-dobra-cisla-alphabetu-za-1q-odrazi-vynosy-z-google-search-youtube-a-cloudovych-sluzeb.html}
}

@online{JohnsonEtAl2016_ScalableBlockedGibbs,
  title = {A {{Scalable Blocked Gibbs Sampling Algorithm For Gaussian And Poisson Regression Models}}},
  author = {Johnson, Nicholas A. and Kuehnel, Frank O. and Amini, Ali Nasiri},
  date = {2016},
  doi = {10.48550/ARXIV.1602.00047},
  url = {https://arxiv.org/abs/1602.00047},
  urldate = {2025-04-20},
  abstract = {Markov Chain Monte Carlo (MCMC) methods are a popular technique in Bayesian statistical modeling. They have long been used to obtain samples from posterior distributions, but recent research has focused on the scalability of these techniques for large problems. We do not develop new sampling methods but instead describe a blocked Gibbs sampler which is sufficiently scalable to accomodate many interesting problems. The sampler we describe applies to a restricted subset of the Generalized Linear Mixed-effects Models (GLMM's); this subset includes Poisson and Gaussian regression models. The blocked Gibbs sampling steps jointly update a prior variance parameter along with all of the random effects underneath it. We also discuss extensions such as flexible prior distributions.},
  pubstate = {prepublished},
  version = {1},
  keywords = {FOS: Computer and information sciences,literatura,Methodology (stat.ME)}
}

@inproceedings{KarrasEtAl2022_DistributedGibbsSampling,
  title = {Distributed {{Gibbs Sampling}} and {{LDA Modelling}} for {{Large Scale Big Data Management}} on {{PySpark}}},
  booktitle = {2022 7th {{South-East Europe Design Automation}}, {{Computer Engineering}}, {{Computer Networks}} and {{Social Media Conference}} ({{SEEDA-CECNSM}})},
  author = {Karras, Christos and Karras, Aristeidis and Tsolis, Dimitrios and Giotopoulos, Konstantinos C. and Sioutas, Spyros},
  date = {2022-09-23},
  pages = {1--8},
  publisher = {IEEE},
  location = {Ioannina, Greece},
  doi = {10.1109/SEEDA-CECNSM57760.2022.9932990},
  url = {https://ieeexplore.ieee.org/document/9932990/},
  urldate = {2025-04-20},
  eventtitle = {2022 7th {{South-East Europe Design Automation}}, {{Computer Engineering}}, {{Computer Networks}} and {{Social Media Conference}} ({{SEEDA-CECNSM}})},
  isbn = {979-8-3503-9858-8},
  keywords = {literatura}
}

@article{KarunarasanEtAl2023_ComparisonBayesianMarkov,
  title = {A Comparison of {{Bayesian Markov}} Chain {{Monte Carlo}} Methods in a Multilevel Scenario},
  author = {Karunarasan, Darshika and Sooriyarachchi, Roshini and Pinto, Vimukthini},
  date = {2023-10-03},
  journaltitle = {Communications in Statistics - Simulation and Computation},
  shortjournal = {Communications in Statistics - Simulation and Computation},
  volume = {52},
  number = {10},
  pages = {4756--4772},
  issn = {0361-0918, 1532-4141},
  doi = {10.1080/03610918.2021.1967985},
  url = {https://www.tandfonline.com/doi/full/10.1080/03610918.2021.1967985},
  urldate = {2025-04-20},
  langid = {english},
  keywords = {literatura}
}

@article{KaufmannFruhwirth-Schnatter2002_BayesianAnalysisSwitching,
  title = {Bayesian Analysis of Switching {{ARCH}} Models},
  author = {Kaufmann, Sylvia and Frühwirth‐Schnatter, Sylvia},
  date = {2002-07},
  journaltitle = {Journal of Time Series Analysis},
  shortjournal = {Journal Time Series Analysis},
  volume = {23},
  number = {4},
  pages = {425--458},
  issn = {0143-9782, 1467-9892},
  doi = {10.1111/1467-9892.00271},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1467-9892.00271},
  urldate = {2025-04-21},
  abstract = {We consider a time series model with autoregressive conditional heteroscedasticity that is subject to changes in regime. The regimes evolve according to a multistate latent Markov switching process with unknown transition probabilities, and it is the constant in the variance process of the innovations that is subject to regime shifts. The joint estimation of the latent process and all model parameters is performed within a Bayesian framework using the method of Markov chain Monte Carlo (MCMC) simulation. We perform model selection with respect to the number of states and the number of autoregressive parameters in the variance process using Bayes factors and model likelihoods. To this aim, the model likelihood is estimated by the method of bridge sampling. The usefulness of the sampler is demonstrated by applying it to the data set previously used by               Hamilton and Susmel (1994               ) who investigated models with switching autoregressive conditional heteroscedasticity using maximum likelihood methods. The paper concludes with some issues related to maximum likelihood methods, to classical model selection, and to potential straightforward extensions of the model presented here.},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\44SA6NXA\Kaufmann a Frühwirth‐Schnatter - 2002 - Bayesian analysis of switching ARCH models.pdf}
}

@article{Kim1998_StochasticVolatilityLH,
  title = {Stochastic Volatility: {{Likelihood}} Inference and Comparison with {{ARCH}} Models},
  author = {Kim, Sangjoon and Shephard, Neil and Chib, Siddhartha},
  date = {1998},
  journaltitle = {The Review of Economic Studies},
  volume = {65},
  number = {3},
  eprint = {2566931},
  eprinttype = {jstor},
  pages = {361--393},
  publisher = {[Oxford University Press, Review of Economic Studies, Ltd.]},
  issn = {00346527, 1467937X},
  url = {http://www.jstor.org/stable/2566931},
  urldate = {2025-04-07},
  abstract = {In this paper, Markov chain Monte Carlo sampling methods are exploited to provide a unified, practical likelihood-based framework for the analysis of stochastic volatility models. A highly effective method is developed that samples all the unobserved volatilities at once using an approximating offset mixture model, followed by an importance reweighting procedure. This approach is compared with several alternative methods using real data. The paper also develops simulation-based methods for filtering, likelihood evaluation and model failure diagnostics. The issue of model choice using non-nested likelihood ratios and Bayes factors is also investigated. These methods are used to compare the fit of stochastic volatility and GARCH models. All the procedures are illustrated in detail.},
  keywords = {literatura}
}

@book{Kruschke2015_DoingBayesianData,
  title = {Doing {{Bayesian}} Data Analysis: A Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  shorttitle = {Doing {{Bayesian}} Data Analysis},
  author = {Kruschke, John K.},
  date = {2015},
  edition = {Edition 2},
  publisher = {Academic Press},
  location = {Boston},
  abstract = {Provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data},
  isbn = {978-0-12-405888-0},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\ECVWJNFU\Kruschke - 2015 - Doing Bayesian data analysis a tutorial with R, J.pdf}
}

@article{KullbackLeibler1951_InformationSufficiency,
  title = {On {{Information}} and {{Sufficiency}}},
  author = {Kullback, S. and Leibler, R. A.},
  date = {1951-03},
  journaltitle = {The Annals of Mathematical Statistics},
  shortjournal = {Ann. Math. Statist.},
  volume = {22},
  number = {1},
  pages = {79--86},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177729694},
  url = {http://projecteuclid.org/euclid.aoms/1177729694},
  urldate = {2025-04-21},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\2R32LRPS\Kullback a Leibler - 1951 - On Information and Sufficiency.pdf}
}

@book{LiangEtAl2010_AdvancedMarkovChain,
  title = {Advanced {{Markov Chain Monte Carlo Methods}}: {{Learning}} from {{Past Samples}}},
  shorttitle = {Advanced {{Markov Chain Monte Carlo Methods}}},
  author = {Liang, Faming and Liu, Chuanhai and Carroll, Raymond J.},
  date = {2010-07-16},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9780470669723},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9780470669723},
  urldate = {2025-04-18},
  isbn = {978-0-470-66972-3},
  langid = {english},
  keywords = {literatura}
}

@article{Liu2024NavigatingTF,
  title = {Navigating the Financial Landscape: {{The}} Power and Limitations of the {{ARIMA}} Model},
  author = {Liu, Jin},
  date = {2024},
  journaltitle = {Highlights in Science, Engineering and Technology},
  url = {https://api.semanticscholar.org/CorpusID:270499508},
  keywords = {literatura}
}

@book{Lowenstein2012_EssentialsHamiltonianDynamics,
  title = {Essentials of {{Hamiltonian}} Dynamics},
  author = {Lowenstein, John H.},
  date = {2012},
  publisher = {Cambridge University Press},
  location = {Cambridge ; New York},
  abstract = {"Classical dynamics is one of the cornerstones of advanced education in physics and applied mathematics, with applications across engineering, chemistry, and biology. In this book, the author uses a concise and pedagogical style to cover all the topics necessary for a graduate-level course in dynamics based on Hamiltonian methods. Readers are introduced to the impressive advances in the field during the second half of the twentieth-century, including KAM theory and deterministic chaos. Essential to these developments are some exciting ideas from modern mathematics, which are introduced carefully and selectively. Core concepts and techniques are discussed, together with numerous concrete examples to illustrate key principles"--},
  isbn = {978-1-107-00520-4},
  pagetotal = {188},
  keywords = {Dynamics,Hamiltonian systems,literatura,SCIENCE / Physics}
}

@article{LuChen2022_BayesianAnalysisLongitudinal,
  title = {Bayesian Analysis of Longitudinal Binary Responses Based on the Multivariate Probit Model: {{A}} Comparison of Five Methods},
  shorttitle = {Bayesian Analysis of Longitudinal Binary Responses Based on the Multivariate Probit Model},
  author = {Lu, Kaifeng and Chen, Fang},
  date = {2022-12},
  journaltitle = {Statistical Methods in Medical Research},
  shortjournal = {Stat Methods Med Res},
  volume = {31},
  number = {12},
  pages = {2261--2286},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/09622802221122403},
  url = {https://journals.sagepub.com/doi/10.1177/09622802221122403},
  urldate = {2025-04-20},
  abstract = {Dichotomous response data observed over multiple time points, especially data that exhibit longitudinal structures, are important in many applied fields. The multivariate probit model has been an attractive tool in such situations for its ability to handle correlations among the outcomes, typically by modeling the covariance (correlation) structure of the latent variables. In addition, a multivariate probit model facilitates controlled imputations for nonignorable dropout, a phenomenon commonly observed in clinical trials of experimental drugs or biologic products. While the model is relatively simple to specify, estimation, particularly from a Bayesian perspective that relies on Markov chain Monte Carlo sampling, is not as straightforward. Here we compare five sampling algorithms for the correlation matrix and discuss their merits: a parameter-expanded Metropolis-Hastings algorithm (Zhang et al., 2006), a parameter-expanded Gibbs sampling algorithm (Talhouk et al., 2012), a parameter-expanded Gibbs sampling algorithm with unit constraints on conditional variances (Tang, 2018), a partial autocorrelation parameterization approach (Gaskins et al., 2014), and a semi-partial correlation parameterization approach (Ghosh et al., 2021). We describe each algorithm, use simulation studies to evaluate their performance, and focus on comparison criteria such as computational cost, convergence time, robustness, and ease of implementations. We find that the parameter-expanded Gibbs sampling algorithm by Talhouk et al. (2012) often has the most efficient convergence with relatively low computational complexity, while the partial autocorrelation parameterization approach is more flexible for estimating the correlation matrix of latent variables for typical late phase longitudinal studies.},
  langid = {english},
  keywords = {literatura}
}

@online{MahaniSharabiani2013_MetropolisHastingsSamplingUsing,
  title = {Metropolis-{{Hastings Sampling Using Multivariate Gaussian Tangents}}},
  author = {Mahani, Alireza S. and Sharabiani, Mansour T. A.},
  date = {2013},
  doi = {10.48550/ARXIV.1308.0657},
  url = {https://arxiv.org/abs/1308.0657},
  urldate = {2025-04-20},
  abstract = {We present MH-MGT, a multivariate technique for sampling from twice-differentiable, log-concave probability density functions. MH-MGT is Metropolis-Hastings sampling using asymmetric, multivariate Gaussian proposal functions constructed from Taylor-series expansion of the log-density function. The mean of the Gaussian proposal function represents the full Newton step, and thus MH-MGT is the stochastic counterpart to Newton optimization. Convergence analysis shows that MH-MGT is well suited for sampling from computationally-expensive log-densities with contributions from many independent observations. We apply the technique to Gibbs sampling analysis of a Hierarchical Bayesian marketing effectiveness model built for a large US foodservice distributor. Compared to univariate slice sampling, MH-MGT shows 6x improvement in sampling efficiency, measured in terms of `function evaluation equivalents per independent sample'. To facilitate wide applicability of MH-MGT to statistical models, we prove that log-concavity of a twice-differentiable distribution is invariant with respect to 'linear-projection' transformations including, but not restricted to, generalized linear models.},
  pubstate = {prepublished},
  version = {1},
  keywords = {65C05 65C60,FOS: Computer and information sciences,literatura,Methodology (stat.ME)}
}

@book{Marek2012_Pravdepodobnost,
  title = {Pravděpodobnost},
  author = {family=Marek, given=Luboš., given-i={{Luboš}}},
  date = {2012},
  edition = {1. vyd},
  publisher = {Professional Publishing},
  location = {Praha},
  isbn = {978-80-7431-087-4},
  langid = {czech},
  keywords = {literatura},
  annotation = {OCLC: 806200448}
}

@online{MbalawataEtAl2013_AdaptiveMetropolisAlgorithm,
  title = {Adaptive {{Metropolis Algorithm Using Variational Bayesian Adaptive Kalman Filter}}},
  author = {Mbalawata, Isambi S. and Särkkä, Simo and Vihola, Matti and Haario, Heikki},
  date = {2013},
  doi = {10.48550/ARXIV.1308.5875},
  url = {https://arxiv.org/abs/1308.5875},
  urldate = {2025-04-18},
  abstract = {Markov chain Monte Carlo (MCMC) methods are powerful computational tools for analysis of complex statistical problems. However, their computational efficiency is highly dependent on the chosen proposal distribution, which is generally difficult to find. One way to solve this problem is to use adaptive MCMC algorithms which automatically tune the statistics of a proposal distribution during the MCMC run. A new adaptive MCMC algorithm, called the variational Bayesian adaptive Metropolis (VBAM) algorithm, is developed. The VBAM algorithm updates the proposal covariance matrix using the variational Bayesian adaptive Kalman filter (VB-AKF). A strong law of large numbers for the VBAM algorithm is proven. The empirical convergence results for three simulated examples and for two real data examples are also provided.},
  pubstate = {prepublished},
  version = {3},
  keywords = {FOS: Mathematics,literatura,Statistics Theory (math.ST)}
}

@book{McElreath2020_StatisticalRethinkingBayesian,
  title = {Statistical Rethinking: A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical Rethinking},
  author = {McElreath, Richard},
  date = {2020},
  series = {Chapman \& {{Hall}}/{{CRC}} Texts in Statistical Science Series},
  edition = {Second edition},
  publisher = {CRC Press},
  location = {Boca Raton},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.},
  isbn = {978-0-367-13991-9},
  pagetotal = {593},
  keywords = {Bayes,Bayes Theorem,Bayes-Entscheidungstheorie,Bayesian statistical decision theory,Computer programs,Computer software,Data Interpretation Statistical,literatura,Logiciels,Mathematical Computing,Mathematics,R,R (Computer program language),R (Langage de programmation),software,Software,Statistisches Modell,Théorème de Bayes,Théorie de la décision bayésienne},
  annotation = {OCLC: on1130764237},
  file = {C:\Users\Michal\Zotero\storage\NWDHKDSR\McElreath - 2020 - Statistical rethinking a Bayesian course with exa.pdf}
}

@article{MetropolisEtAl1953_EquationStateCalculations,
  title = {Equation of {{State Calculations}} by {{Fast Computing Machines}}},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  date = {1953-06-01},
  journaltitle = {The Journal of Chemical Physics},
  volume = {21},
  number = {6},
  pages = {1087--1092},
  issn = {0021-9606, 1089-7690},
  doi = {10.1063/1.1699114},
  url = {https://pubs.aip.org/jcp/article/21/6/1087/202680/Equation-of-State-Calculations-by-Fast-Computing},
  urldate = {2025-04-18},
  abstract = {A general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. The method consists of a modified Monte Carlo integration over configuration space. Results for the two-dimensional rigid-sphere system have been obtained on the Los Alamos MANIAC and are presented here. These results are compared to the free volume equation of state and to a four-term virial coefficient expansion.},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\PW2U8HWR\Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing Machines.pdf}
}

@online{MurakamiEtAl2025_RapidComprehensiveSearch,
  title = {Rapid, {{Comprehensive Search}} of {{Crystalline Phases}} from {{X-ray Diffraction}} in {{Seconds}} via {{GPU-Accelerated Bayesian Variational Inference}}},
  author = {Murakami, Ryo and Nagata, Kenji and Matsushita, Yoshitaka and Demura, Masahiko},
  date = {2025},
  doi = {10.48550/ARXIV.2501.09308},
  url = {https://arxiv.org/abs/2501.09308},
  urldate = {2025-04-21},
  abstract = {In analysis of X-ray diffraction data, identifying the crystalline phase is important for interpreting the material. The typical method is identifying the crystalline phase from the coincidence of the main diffraction peaks. This method identifies crystalline phases by matching them as individual crystalline phases rather than as combinations of crystalline phases, in the same way as the greedy method. If multiple candidates are obtained, the researcher must subjectively select the crystalline phases. Thus, the identification results depend on the researcher's experience and knowledge of materials science. To solve this problem, we have developed a Bayesian estimation method to identify the combination of crystalline phases, taking the entire profile into account. This method estimates the Bayesian posterior probability of crystalline phase combinations by performing an approximate exhaustive search of all possible combinations. It is a method for identifying crystalline phases that takes into account all peak shapes and phase combinations. However, it takes a few hours to obtain the analysis results. The aim of this study is to develop a Bayesian method for crystalline phase identification that can provide results in seconds, which is a practical calculation time. We introduce variational sparse estimation and GPU computing. Our method is able to provide results within 10 seconds even when analysing \$2\textasciicircum\{50\}\$ candidate crystalline phase combinations. Furthermore, the crystalline phases identified by our method are consistent with the results of previous studies that used a high-precision algorithm.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Applications (stat.AP),Computational Physics (physics.comp-ph),FOS: Computer and information sciences,FOS: Physical sciences,literatura,Materials Science (cond-mat.mtrl-sci)}
}

@article{Nelson1991_ConditionalHeteroskedasticityAsset,
  title = {Conditional Heteroskedasticity in Asset Returns: A New Approach},
  author = {Nelson, Daniel B.},
  date = {1991},
  journaltitle = {Econometrica : journal of the Econometric Society},
  shortjournal = {Econometrica},
  volume = {59},
  number = {2},
  eprint = {2938260},
  eprinttype = {jstor},
  pages = {347--370},
  publisher = {[Wiley, Econometric Society]},
  issn = {00129682, 14680262},
  url = {http://www.jstor.org/stable/2938260},
  urldate = {2025-04-30},
  abstract = {GARCH models have been applied in modelling the relation between conditional variance and asset risk premia. These models, however, have at least three major drawbacks in asset pricing applications: (i) Researchers beginning with Black (1976) have found a negative correlation between current returns and future returns volatility. GARCH models rule this out by assumption. (ii) GARCH models impose parameter restrictions that are often violated by estimated coefficients and that may unduly restrict the dynamics of the conditional variance process. (iii) Interpreting whether shocks to conditional variance "persist" or not is difficult in GARCH models, because the usual norms measuring persistence often do not agree. A new form of ARCH is proposed that meets these objections. The method is used to estimate a model of the risk premium on the CRSP Value-Weighted Market Index from 1962 to 1987.},
  keywords = {literatura}
}

@thesis{ranganath2017black,
  type = {phdthesis},
  title = {Black Box Variational Inference: {{Scalable}}, Generic {{Bayesian}} Computation and Its Applications},
  author = {Ranganath, Rajesh},
  date = {2017},
  institution = {Princeton University},
  location = {Princeton, NJ},
  url = {http://arks.princeton.edu/ark:/88435/dsp01pr76f608w},
  keywords = {literatura}
}

@manual{RCoreTeam2023_LanguageEnvironmentStatistical,
  type = {manual},
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  date = {2023},
  publisher = {R Foundation for Statistical Computing},
  location = {Vienna, Austria},
  url = {https://www.R-project.org/},
  keywords = {literatura}
}

@manual{RyanUlrich2025_QuantmodQuantitativeFinancial,
  type = {manual},
  title = {Quantmod: {{Quantitative}} Financial Modelling Framework},
  author = {Ryan, Jeffrey A. and Ulrich, Joshua M.},
  date = {2025},
  url = {https://CRAN.R-project.org/package=quantmod},
  keywords = {balicek}
}

@inproceedings{Sawyer2018ModelingPE,
  title = {Modeling Player Engagement with Bayesian Hierarchical Models},
  booktitle = {Artificial Intelligence and Interactive Digital Entertainment Conference},
  author = {Sawyer, R. Keith and Rowe, Jonathan P. and Azevedo, Roger and Lester, James C.},
  date = {2018},
  url = {https://api.semanticscholar.org/CorpusID:52236139},
  keywords = {literatura}
}

@book{ShumwayStoffer2017_TimeSeriesAnalysis,
  title = {Time {{Series Analysis}} and {{Its Applications}}: {{With R Examples}}},
  shorttitle = {Time {{Series Analysis}} and {{Its Applications}}},
  author = {Shumway, Robert H. and Stoffer, David S.},
  date = {2017},
  series = {Springer {{Texts}} in {{Statistics}}},
  edition = {4th ed. 2017},
  publisher = {Springer},
  location = {Cham},
  doi = {10.1007/978-3-319-52452-8},
  isbn = {978-3-319-52452-8},
  langid = {english},
  pagetotal = {562},
  keywords = {literatura}
}

@online{Sjolund2023_TutorialParametricVariational,
  title = {A {{Tutorial}} on {{Parametric Variational Inference}}},
  author = {Sjölund, Jens},
  date = {2023},
  doi = {10.48550/ARXIV.2301.01236},
  url = {https://arxiv.org/abs/2301.01236},
  urldate = {2024-11-03},
  abstract = {Variational inference uses optimization, rather than integration, to approximate the marginal likelihood, and thereby the posterior, in a Bayesian model. Thanks to advances in computational scalability made in the last decade, variational inference is now the preferred choice for many high-dimensional models and large datasets. This tutorial introduces variational inference from the parametric perspective that dominates these recent developments, in contrast to the mean-field perspective commonly found in other introductory texts.},
  pubstate = {prepublished},
  version = {1},
  keywords = {FOS: Computer and information sciences,literatura,Machine Learning (cs.LG),Machine Learning (stat.ML),Methodology (stat.ME)}
}

@misc{StanDevelopmentTeam2024_RStanInterfaceStan,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  date = {2024},
  url = {https://mc-stan.org/},
  keywords = {balicek}
}

@article{Timpson2008_QuantumBayesianismStudy,
  title = {Quantum {{Bayesianism}}: {{A}} Study},
  shorttitle = {Quantum {{Bayesianism}}},
  author = {Timpson, Christopher Gordon},
  date = {2008-09},
  journaltitle = {Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics},
  shortjournal = {Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics},
  volume = {39},
  number = {3},
  pages = {579--609},
  issn = {13552198},
  doi = {10.1016/j.shpsb.2008.03.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1355219808000257},
  urldate = {2025-04-21},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\YGRQWJG7\Timpson - 2008 - Quantum Bayesianism A study.pdf}
}

@book{Tsay2005_AnalysisFinancialTime,
  title = {Analysis of Financial Time Series},
  author = {Tsay, Ruey S.},
  date = {2005},
  edition = {2nd ed},
  publisher = {Wiley},
  location = {Hoboken, N.J},
  isbn = {978-0-471-69074-0},
  pagetotal = {605},
  keywords = {Econometrics,literatura,Risk management,Time-series analysis}
}

@book{Vickers2010_WhatPvalueAnyway,
  title = {What Is a {{P-value}} Anyway? 34 Stories to Help You Actually Understand Statistics},
  shorttitle = {What Is a {{P-value}} Anyway?},
  author = {Vickers, Andrew},
  date = {2010},
  publisher = {Addison-Wesley},
  location = {Boston},
  isbn = {978-0-321-62930-2},
  pagetotal = {212},
  keywords = {literatura,Mathematical statistics},
  annotation = {OCLC: ocn319602638}
}

@article{VirbickaiteEtAl2015_BAYESIANINFERENCEMETHODS,
  title = {{{BAYESIAN INFERENCE METHODS FOR UNIVARIATE AND MULTIVARIATE GARCH MODELS}}: {{A SURVEY}}},
  shorttitle = {{{BAYESIAN INFERENCE METHODS FOR UNIVARIATE AND MULTIVARIATE GARCH MODELS}}},
  author = {Virbickaite, Audrone and Ausín, M. Concepción and Galeano, Pedro},
  date = {2015-02},
  journaltitle = {Journal of Economic Surveys},
  shortjournal = {Journal of Economic Surveys},
  volume = {29},
  number = {1},
  pages = {76--96},
  issn = {0950-0804, 1467-6419},
  doi = {10.1111/joes.12046},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/joes.12046},
  urldate = {2025-04-21},
  abstract = {Abstract             This survey reviews the existing literature on the most relevant Bayesian inference methods for univariate and multivariate GARCH models. The advantages and drawbacks of each procedure are outlined as well as the advantages of the Bayesian approach versus classical procedures. The paper makes emphasis on recent Bayesian non‐parametric approaches for GARCH models that avoid imposing arbitrary parametric distributional assumptions. These novel approaches implicitly assume infinite mixture of Gaussian distributions on the standardized returns which have been shown to be more flexible and describe better the uncertainty about future volatilities. Finally, the survey presents an illustration using real data to show the flexibility and usefulness of the non‐parametric approach.},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\5VC57A9C\Virbickaite et al. - 2015 - BAYESIAN INFERENCE METHODS FOR UNIVARIATE AND MULTIVARIATE GARCH MODELS A SURVEY.pdf}
}

@online{Vishnoi2021_IntroductionHamiltonianMonte,
  title = {An {{Introduction}} to {{Hamiltonian Monte Carlo Method}} for {{Sampling}}},
  author = {Vishnoi, Nisheeth K.},
  date = {2021},
  doi = {10.48550/ARXIV.2108.12107},
  url = {https://arxiv.org/abs/2108.12107},
  urldate = {2024-11-03},
  abstract = {The goal of this article is to introduce the Hamiltonian Monte Carlo (HMC) method -- a Hamiltonian dynamics-inspired algorithm for sampling from a Gibbs density \$π(x) \textbackslash propto e\textasciicircum\{-f(x)\}\$. We focus on the "idealized" case, where one can compute continuous trajectories exactly. We show that idealized HMC preserves \$π\$ and we establish its convergence when \$f\$ is strongly convex and smooth.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computation (stat.CO),Data Structures and Algorithms (cs.DS),FOS: Computer and information sciences,FOS: Mathematics,literatura,Machine Learning (cs.LG),Machine Learning (stat.ML),Probability (math.PR)}
}

@article{WassersteinEtAl2019_MovingWorld005,
  title = {Moving to a {{World Beyond}} “ {\mkbibemph{p}} {$<$} 0.05”},
  author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
  date = {2019-03-29},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {73},
  pages = {1--19},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2019.1583913},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913},
  urldate = {2024-11-01},
  issue = {sup1},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\F62ZECYQ\Wasserstein et al. - 2019 - Moving to a World Beyond “ p  0.05”.pdf}
}

@book{Wickham2016_Ggplot2ElegantGraphics,
  title = {Ggplot2: {{Elegant}} Graphics for Data Analysis},
  author = {Wickham, Hadley},
  date = {2016},
  publisher = {Springer-Verlag New York},
  url = {https://ggplot2.tidyverse.org},
  isbn = {978-3-319-24277-4},
  keywords = {balicek}
}

@manual{WickhamEtAl2023_DplyrGrammarData,
  type = {manual},
  title = {Dplyr: A Grammar of Data Manipulation},
  author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill and Vaughan, Davis},
  date = {2023},
  url = {https://dplyr.tidyverse.org},
  keywords = {balicek}
}

@manual{WickhamEtAl2024_TidyrTidyMessy,
  type = {manual},
  title = {Tidyr: {{Tidy}} Messy Data},
  author = {Wickham, Hadley and Vaughan, Davis and Girlich, Maximilian},
  date = {2024},
  url = {https://tidyr.tidyverse.org},
  keywords = {balicek}
}

@manual{WickhamHenry2025_PurrrFunctionalProgramming,
  type = {manual},
  title = {Purrr: {{Functional}} Programming Tools},
  author = {Wickham, Hadley and Henry, Lionel},
  date = {2025},
  url = {https://purrr.tidyverse.org/},
  keywords = {balicek}
}

@book{Wooldridge2020_IntroductoryEconometricsModern,
  title = {Introductory Econometrics: A Modern Approach},
  shorttitle = {Introductory Econometrics},
  author = {Wooldridge, Jeffrey M.},
  date = {2020},
  edition = {Seventh edition},
  publisher = {Cengage},
  location = {Boston, MA},
  isbn = {978-1-337-55886-0},
  langid = {english},
  pagetotal = {826},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\ERC77IE6\Wooldridge - 2020 - Introductory econometrics a modern approach.pdf}
}

@online{WSJ2023_StockMarketNews,
  title = {Stock {{Market News}}, {{Oct}}. 25, 2023: {{Nasdaq Closes}} in {{Correction Territory}}; {{Alphabet Stock Slides After Earnings}}},
  shorttitle = {Stock {{Market News}}, {{Oct}}. 25, 2023},
  author = {WSJ},
  date = {2023-10-25},
  url = {https://www.wsj.com/livecoverage/stock-market-today-dow-jones-10-25-2023},
  urldate = {2025-04-24},
  abstract = {Facebook parent Meta reports results later today},
  langid = {american},
  organization = {WSJ},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\IQWI7CHD\stock-market-today-dow-jones-10-25-2023.html}
}

@online{WuEtAl2018_FasterHamiltonianMonte,
  title = {Faster {{Hamiltonian Monte Carlo}} by {{Learning Leapfrog Scale}}},
  author = {Wu, Changye and Stoehr, Julien and Robert, Christian P.},
  date = {2018},
  doi = {10.48550/ARXIV.1810.04449},
  url = {https://arxiv.org/abs/1810.04449},
  urldate = {2025-04-20},
  abstract = {Hamiltonian Monte Carlo samplers have become standard algorithms for MCMC implementations, as opposed to more basic versions, but they still require some amount of tuning and calibration. Exploiting the U-turn criterion of the NUTS algorithm (Hoffman and Gelman, 2014), we propose a version of HMC that relies on the distribution of the integration time of the associated leapfrog integrator. Using in addition the primal-dual averaging method for tuning the step size of the integrator, we achieve an essentially calibration free version of HMC. When compared with the original NUTS on several benchmarks, this algorithm exhibits a significantly improved efficiency.},
  pubstate = {prepublished},
  version = {2},
  keywords = {Computation (stat.CO),Data Structures and Algorithms (cs.DS),FOS: Computer and information sciences,literatura}
}

@article{Zabell2022_FisherBayesPredictive,
  title = {Fisher, {{Bayes}}, and {{Predictive Inference}}},
  author = {Zabell, Sandy},
  date = {2022-05-11},
  journaltitle = {Mathematics},
  shortjournal = {Mathematics},
  volume = {10},
  number = {10},
  pages = {1634},
  issn = {2227-7390},
  doi = {10.3390/math10101634},
  url = {https://www.mdpi.com/2227-7390/10/10/1634},
  urldate = {2025-04-21},
  abstract = {We review historically the position of Sir R.A. Fisher towards Bayesian inference and, particularly, the classical Bayes–Laplace paradigm. We focus on his Fiducial Argument.},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\4A59BPJX\Zabell - 2022 - Fisher, Bayes, and Predictive Inference.pdf}
}

@article{ZeileisGrothendieck2005_ZooS3Infrastructure,
  title = {Zoo: {{S3}} Infrastructure for Regular and Irregular Time Series},
  author = {Zeileis, Achim and Grothendieck, Gabor},
  date = {2005},
  journaltitle = {Journal of Statistical Software},
  volume = {14},
  number = {6},
  pages = {1--27},
  doi = {10.18637/jss.v014.i06},
  keywords = {balicek}
}

@online{ZhangEtAl2024_PathIntegralMonte,
  title = {Path Integral {{Monte Carlo}} in a Discrete Variable Representation with {{Gibbs}} Sampling: Dipolar Planar Rotor Chain},
  shorttitle = {Path Integral {{Monte Carlo}} in a Discrete Variable Representation with {{Gibbs}} Sampling},
  author = {Zhang, Wenxue and Moeed, Muhammad Shaeer and Bright, Andrew and Serwatka, Tobias and De Oliveira, Estevao and Roy, Pierre-Nicholas},
  date = {2024},
  doi = {10.48550/ARXIV.2410.13633},
  url = {https://arxiv.org/abs/2410.13633},
  urldate = {2025-04-20},
  abstract = {In this work, we propose a Path Integral Monte Carlo (PIMC) approach based on discretized continuous degrees of freedom and rejection-free Gibbs sampling. The ground state properties of a chain of planar rotors with dipole-dipole interactions are used to illustrate the approach. Energetic and structural properties are computed and compared to exact diagonalization and Numerical Matrix Multiplication for \$N \textbackslash leq 3\$ to assess the systematic Trotter factorization error convergence. For larger chains with up to N = 100 rotors, Density Matrix Renormalization Group (DMRG) calculations are used as a benchmark. We show that using Gibbs sampling is advantageous compared to traditional Metroplolis-Hastings rejection importance sampling. Indeed, Gibbs sampling leads to lower variance and correlation in the computed observables.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Atomic and Molecular Clusters (physics.atm-clus),Chemical Physics (physics.chem-ph),FOS: Physical sciences,literatura,Mesoscale and Nanoscale Physics (cond-mat.mes-hall),Quantum Physics (quant-ph),Statistical Mechanics (cond-mat.stat-mech)}
}
