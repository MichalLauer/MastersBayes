@article{AL-Najjar2016_ModellingEstimationVolatility,
  title = {Modelling and {{Estimation}} of {{Volatility Using ARCH}}/{{GARCH Models}} in {{Jordan}}’s {{Stock Market}}},
  author = {AL-Najjar, Dana Mohammad},
  date = {2016-05-06},
  journaltitle = {Asian Journal of Finance \& Accounting},
  shortjournal = {AJFA},
  volume = {8},
  number = {1},
  pages = {152},
  issn = {1946-052X},
  doi = {10.5296/ajfa.v8i1.9129},
  url = {http://www.macrothink.org/journal/index.php/ajfa/article/view/9129},
  urldate = {2025-04-05},
  abstract = {{$<$}p{$>$}Financials have been concerned constantly with factors that have impact on both taking and assessing various financial decisions in firms. Hence modelling volatility in financial markets is one of the factors that have direct role and effect on pricing, risk and portfolio management. Therefore, this study aims to examine the volatility characteristics on Jordan’s capital market that include; clustering volatility, leptokurtosis, and leverage effect. This objective can be accomplished by selecting symmetric and asymmetric models from GARCH family models. This study applies; ARCH, GARCH, and EGARCH to investigate the behavior of stock return volatility for Amman Stock Exchange (ASE) covering the period from Jan. 1 2005 through Dec.31 2014. The main findings suggest that the symmetric ARCH /GARCH models can capture characteristics of ASE, and provide more evidence for both volatility clustering and leptokurtic, whereas EGARCH output reveals no support for the existence of leverage effect in the stock returns at Amman Stock Exchange.{$<$}/p{$>$}},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\YE9E22T5\AL-Najjar - 2016 - Modelling and Estimation of Volatility Using ARCHGARCH Models in Jordan’s Stock Market.pdf}
}

@article{AndradeFernandez2016_InterpretationConfidenceInterval,
  title = {Interpretation of {{Confidence Interval Facing}} the {{Conflict}}},
  author = {Andrade, Luisa and Fernández, Felipe},
  date = {2016-12},
  journaltitle = {Universal Journal of Educational Research},
  shortjournal = {ujer},
  volume = {4},
  number = {12},
  pages = {2687--2700},
  issn = {2332-3205, 2332-3213},
  doi = {10.13189/ujer.2016.041201},
  url = {http://www.hrpub.org/journals/article_info.php?aid=5357},
  urldate = {2025-04-13},
  langid = {english},
  keywords = {literatura}
}

@online{BartosEtAl2024_FairCoinsTend,
  title = {Fair Coins Tend to Land on the Same Side They Started: {{Evidence}} from 350,757 Flips},
  shorttitle = {Fair Coins Tend to Land on the Same Side They Started},
  author = {Bartoš, František and Sarafoglou, Alexandra and Godmann, Henrik R. and Sahrani, Amir and Leunk, David Klein and Gui, Pierre Y. and Voss, David and Ullah, Kaleem and Zoubek, Malte J. and Nippold, Franziska and Aust, Frederik and Vieira, Felipe F. and Islam, Chris-Gabriel and Zoubek, Anton J. and Shabani, Sara and Petter, Jonas and Roos, Ingeborg B. and Finnemann, Adam and Lob, Aaron B. and Hoffstadt, Madlen F. and Nak, Jason and family=Ron, given=Jill, prefix=de, useprefix=false and Derks, Koen and Huth, Karoline and Terpstra, Sjoerd and Bastelica, Thomas and Matetovici, Magda and Ott, Vincent L. and Zetea, Andreea S. and Karnbach, Katharina and Donzallaz, Michelle C. and John, Arne and Moore, Roy M. and Assion, Franziska and family=Bork, given=Riet, prefix=van, useprefix=false and Leidinger, Theresa E. and Zhao, Xiaochang and Motaghi, Adrian Karami and Pan, Ting and Armstrong, Hannah and Peng, Tianqi and Bialas, Mara and Pang, Joyce Y.-C. and Fu, Bohan and Yang, Shujun and Lin, Xiaoyi and Sleiffer, Dana and Bognar, Miklos and Aczel, Balazs and Wagenmakers, Eric-Jan},
  date = {2024-06-02},
  eprint = {2310.04153},
  eprinttype = {arXiv},
  eprintclass = {math},
  url = {http://arxiv.org/abs/2310.04153},
  abstract = {Many people have flipped coins but few have stopped to ponder the statistical and physical intricacies of the process. In a preregistered study we collected \$350\{,\}757\$ coin flips to test the counterintuitive prediction from a physics model of human coin tossing developed by Diaconis, Holmes, and Montgomery (DHM; 2007). The model asserts that when people flip an ordinary coin, it tends to land on the same side it started -- DHM estimated the probability of a same-side outcome to be about 51\%. Our data lend strong support to this precise prediction: the coins landed on the same side more often than not, \$\textbackslash text\{Pr\}(\textbackslash text\{same side\}) = 0.508\$, 95\% credible interval (CI) [\$0.506\$, \$0.509\$], \$\textbackslash text\{BF\}\_\{\textbackslash text\{same-side bias\}\} = 2359\$. Furthermore, the data revealed considerable between-people variation in the degree of this same-side bias. Our data also confirmed the generic prediction that when people flip an ordinary coin -- with the initial side-up randomly determined -- it is equally likely to land heads or tails: \$\textbackslash text\{Pr\}(\textbackslash text\{heads\}) = 0.500\$, 95\% CI [\$0.498\$, \$0.502\$], \$\textbackslash text\{BF\}\_\{\textbackslash text\{heads-tails bias\}\} = 0.182\$. Furthermore, this lack of heads-tails bias does not appear to vary across coins. Additional exploratory analyses revealed that the within-people same-side bias decreased as more coins were flipped, an effect that is consistent with the possibility that practice makes people flip coins in a less wobbly fashion. Our data therefore provide strong evidence that when some (but not all) people flip a fair coin, it tends to land on the same side it started. Our data provide compelling statistical support for the DHM physics model of coin tossing.},
  pubstate = {prepublished},
  keywords = {literatura,Mathematics - History and Overview,Physics - Data Analysis Statistics and Probability,Statistics - Other Statistics},
  file = {C\:\\Users\\Michal\\Zotero\\storage\\D8BS2H95\\Bartoš et al. - 2024 - Fair coins tend to land on the same side they star.pdf;C\:\\Users\\Michal\\Zotero\\storage\\TFVHAQSC\\2310.html}
}

@article{Bollerslev1986_GeneralizedAutoregressiveConditional,
  title = {Generalized Autoregressive Conditional Heteroskedasticity},
  author = {Bollerslev, Tim},
  date = {1986-04},
  journaltitle = {Journal of Econometrics},
  shortjournal = {Journal of Econometrics},
  volume = {31},
  number = {3},
  pages = {307--327},
  issn = {03044076},
  doi = {10.1016/0304-4076(86)90063-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0304407686900631},
  urldate = {2025-04-13},
  langid = {english},
  keywords = {literatura}
}

@article{CampbellEtAl1998_ECONOMETRICSFINANCIALMARKETS,
  title = {{{THE ECONOMETRICS OF FINANCIAL MARKETS}}},
  author = {Campbell, John Y. and Lo, Andrew W. and MacKinlay, A. Craig and Whitelaw, Robert F.},
  date = {1998-12},
  journaltitle = {Macroeconomic Dynamics},
  shortjournal = {Macroecon. Dynam.},
  volume = {2},
  number = {4},
  pages = {559--562},
  issn = {1365-1005, 1469-8056},
  doi = {10.1017/S1365100598009092},
  url = {https://www.cambridge.org/core/product/identifier/S1365100598009092/type/journal_article},
  urldate = {2025-03-26},
  abstract = {This book is an ambitious effort by three well-known and well-respected scholars to fill an acknowledged void in the literature—a text covering the burgeoning  field of empirical finance. As the authors note in the preface, there are several excellent books covering financial theory at a level suitable for a Ph.D. class or as a reference for academics and practitioners, but there is little or nothing similar that covers econometric methods and applications. Perhaps the closest existing text is the recent addition to the Wiley               Series in Financial and Quantitative Analysis               .  written by Cuthbertson (1996). The major difference between the books is that Cuthbertson focuses exclusively on asset pricing in the stock, bond, and foreign exchange markets, whereas Campbell, Lo, and MacKinlay (henceforth CLM) consider empirical applications throughout the field of finance, including corporate finance, derivatives markets, and market microstructure. The level of anticipation preceding publication can be partly measured by the fact that at least three reviews (including this one) have appeared since the book arrived. Moreover, in their reviews, both Harvey (1998) and Tiso (1998) comment on the need for such a text, a sentiment that has been echoed by numerous finance academics.},
  langid = {english},
  keywords = {literatura}
}

@incollection{Cont2007_VolatilityClusteringFinancial,
  title = {Volatility {{Clustering}} in {{Financial Markets}}: {{Empirical Facts}} and {{Agent-Based Models}}},
  shorttitle = {Volatility {{Clustering}} in {{Financial Markets}}},
  booktitle = {Long {{Memory}} in {{Economics}}},
  author = {Cont, Rama},
  editor = {Teyssière, Gilles and Kirman, Alan P.},
  date = {2007},
  pages = {289--309},
  publisher = {Springer Berlin Heidelberg},
  doi = {10.1007/978-3-540-34625-8_10},
  url = {http://link.springer.com/10.1007/978-3-540-34625-8_10},
  urldate = {2025-03-31},
  isbn = {978-3-540-22694-9},
  langid = {english},
  keywords = {literatura}
}

@article{DepaoliVanDeSchoot2017_ImprovingTransparencyReplication,
  title = {Improving Transparency and Replication in {{Bayesian}} Statistics: {{The WAMBS-Checklist}}.},
  shorttitle = {Improving Transparency and Replication in {{Bayesian}} Statistics},
  author = {Depaoli, Sarah and Van De Schoot, Rens},
  date = {2017-06},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {22},
  number = {2},
  pages = {240--261},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000065},
  url = {https://doi.apa.org/doi/10.1037/met0000065},
  urldate = {2025-04-13},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\XXMNXRLC\Depaoli a Van De Schoot - 2017 - Improving transparency and replication in Bayesian statistics The WAMBS-Checklist..pdf}
}

@book{FernandezRodriguez2020_ModelingVolatilityReturns,
  title = {Modeling the {{Volatility}} of {{Returns}} on {{Commodities}}: {{An Application}} and {{Empirical Comparison}} of {{GARCH}} and {{SV Models}}},
  shorttitle = {Modeling the {{Volatility}} of {{Returns}} on {{Commodities}}},
  author = {Fernández, Jean and Rodríguez, Gabriel},
  date = {2020},
  series = {Documento de Trabajo},
  publisher = {Pontificia Universidad Católica del Perú},
  doi = {10.18800/2079-8474.0484},
  url = {http://repositorio.pucp.edu.pe/index/handle/123456789/176225},
  urldate = {2025-04-08},
  abstract = {Se utilizan siete modelos GARCH y de volatilidad estocástica (SV) para modelar y comparar empíricamente la volatilidad de los rendimientos de cuatro materias primas: oro, cobre, petróleo y gas natural. Los resultados muestran evidencia de colas gruesas y saltos aleatorios creados por desequilibrios de oferta / demanda, episodios de inestabilidad internacional, tensiones geopolíticas y especulación de mercado, entre otros factores. También encontramos evidencia de un efecto apalancamiento en el petróleo y el cobre, derivado de su dependencia de la actividad económica mundial; y de un efecto apalancamiento inverso en oro y gas natural, consistente con el papel del primero como activo seguro y con la incertidumbre sobre la oferta futura del segundo. Además, en la mayoría de los casos no hay evidencia de un impacto de la volatilidad en la media. Finalmente, encontramos que los modelos de volatilidad de rendimiento con mejor desempeño son GARCH-t para el oro.},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\RBYNAVNX\Fernández a Rodríguez - 2020 - Modeling the Volatility of Returns on Commodities An Application and Empirical Comparison of GARCH.pdf}
}

@book{Gelman2014_BayesianDataAnalysis,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew},
  date = {2014},
  series = {Chapman \& {{Hall}}/{{CRC}} Texts in Statistical Science},
  edition = {Third edition},
  publisher = {CRC Press},
  location = {Boca Raton},
  abstract = {"Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"--},
  isbn = {978-1-4398-4095-5},
  pagetotal = {661},
  keywords = {Bayesian statistical decision theory,literatura,MATHEMATICS / Probability & Statistics / General},
  file = {C:\Users\Michal\Zotero\storage\UQD7XY6P\Gelman - 2014 - Bayesian data analysis.pdf}
}

@incollection{GelmanEtAl1996_EfficientMetropolisJumping,
  title = {Efficient {{Metropolis Jumping Rules}}},
  booktitle = {Bayesian {{Statistics}} 5},
  author = {Gelman, A and Roberts, G O and Gilks, W R},
  editor = {Bernardo, J M and Berger, J O and Dawid, A P and Smith, A F M},
  date = {1996-05-09},
  pages = {599--608},
  publisher = {Oxford University PressOxford},
  doi = {10.1093/oso/9780198523567.003.0038},
  url = {https://academic.oup.com/book/54042/chapter/422210114},
  urldate = {2025-04-18},
  abstract = {Abstract             The algorithm of Metropolis et al. (1953) and its generalizations have been increasingly popular in computational physics and, more recently, statistics, for sampling from intractable multivariate distributions. Much recent research has been devoted to increasing the efficiency of simulation algorithms by altering the jumping rules for Metropolis-like algorithms. We study a very specific question: What are the most efficient symmetric jumping kernels for simulating a normal target distribution using the Metropolis algorithmã We provide a general theoretical result as the dimension of a class of canonical problems goes to ∞ and numerical approximations and simulations for low-dimensional Gaussian target distributions that show that the limiting results provide extremely accurate approximations in six and higher dimensions.},
  isbn = {978-0-19-852356-7},
  langid = {english},
  keywords = {literatura}
}

@online{GelmanEtAl2020_BayesianWorkflow,
  title = {Bayesian {{Workflow}}},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and Bürkner, Paul-Christian and Modrák, Martin},
  date = {2020-11-03},
  eprint = {2011.01808},
  eprinttype = {arXiv},
  eprintclass = {stat},
  url = {http://arxiv.org/abs/2011.01808},
  urldate = {2024-09-03},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  pubstate = {prepublished},
  keywords = {literatura,Statistics - Methodology},
  file = {C\:\\Users\\Michal\\Zotero\\storage\\F6I5R5TZ\\Gelman et al. - 2020 - Bayesian Workflow.pdf;C\:\\Users\\Michal\\Zotero\\storage\\WH2K5CX8\\2011.html}
}

@article{GelmanStern2006_DifferenceSignificantNot,
  title = {The {{Difference Between}} “{{Significant}}” and “{{Not Significant}}” Is Not {{Itself Statistically Significant}}},
  author = {Gelman, Andrew and Stern, Hal},
  date = {2006-11},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {60},
  number = {4},
  pages = {328--331},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/000313006X152649},
  url = {http://www.tandfonline.com/doi/abs/10.1198/000313006X152649},
  urldate = {2024-12-02},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\YXIPUKC6\gelman2006.pdf}
}

@book{Hebak2013_StatistickeMysleniNastroje,
  title = {Statistické myšlení a nástroje analýzy dat},
  author = {Hebák, Petr},
  date = {2013},
  edition = {Vyd. 1},
  publisher = {Informatorium},
  location = {Praha},
  isbn = {978-80-7333-105-4},
  langid = {czech},
  keywords = {literatura},
  annotation = {OCLC: 883371397}
}

@online{HeEtAl2016_ScanOrderGibbs,
  title = {Scan {{Order}} in {{Gibbs Sampling}}: {{Models}} in {{Which}} It {{Matters}} and {{Bounds}} on {{How Much}}},
  shorttitle = {Scan {{Order}} in {{Gibbs Sampling}}},
  author = {He, Bryan and De Sa, Christopher and Mitliagkas, Ioannis and Ré, Christopher},
  date = {2016},
  doi = {10.48550/ARXIV.1606.03432},
  url = {https://arxiv.org/abs/1606.03432},
  urldate = {2025-04-20},
  abstract = {Gibbs sampling is a Markov Chain Monte Carlo sampling technique that iteratively samples variables from their conditional distributions. There are two common scan orders for the variables: random scan and systematic scan. Due to the benefits of locality in hardware, systematic scan is commonly used, even though most statistical guarantees are only for random scan. While it has been conjectured that the mixing times of random scan and systematic scan do not differ by more than a logarithmic factor, we show by counterexample that this is not the case, and we prove that that the mixing times do not differ by more than a polynomial factor under mild conditions. To prove these relative bounds, we introduce a method of augmenting the state space to study systematic scan using conductance.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,literatura,Machine Learning (cs.LG),Machine Learning (stat.ML)}
}

@book{HindlsEtAl2018_StatistikaEkonomii,
  title = {Statistika v ekonomii},
  author = {Hindls, Richard and Arltová, Markéta and Hronová, Stanislava and Malá, Ivana and Marek, Luboš and Pecáková, Iva and Řezanková, Hana},
  date = {2018},
  isbn = {978-80-88260-09-7},
  langid = {czech},
  keywords = {literatura},
  annotation = {OCLC: 1066057734}
}

@article{HopkinsEtAl2024_HowWeKnow,
  title = {How {{Do We Know What We Know}}? {{Learning}} from {{Monte Carlo Simulations}}},
  shorttitle = {How {{Do We Know What We Know}}?},
  author = {Hopkins, Vincent and Kagalwala, Ali and Philips, Andrew Q. and Pickup, Mark and Whitten, Guy D.},
  date = {2024-01-01},
  journaltitle = {The Journal of Politics},
  shortjournal = {The Journal of Politics},
  volume = {86},
  number = {1},
  pages = {36--53},
  issn = {0022-3816, 1468-2508},
  doi = {10.1086/726934},
  url = {https://www.journals.uchicago.edu/doi/10.1086/726934},
  urldate = {2025-04-18},
  langid = {english},
  keywords = {literatura}
}

@online{JohnsonEtAl2016_ScalableBlockedGibbs,
  title = {A {{Scalable Blocked Gibbs Sampling Algorithm For Gaussian And Poisson Regression Models}}},
  author = {Johnson, Nicholas A. and Kuehnel, Frank O. and Amini, Ali Nasiri},
  date = {2016},
  doi = {10.48550/ARXIV.1602.00047},
  url = {https://arxiv.org/abs/1602.00047},
  urldate = {2025-04-20},
  abstract = {Markov Chain Monte Carlo (MCMC) methods are a popular technique in Bayesian statistical modeling. They have long been used to obtain samples from posterior distributions, but recent research has focused on the scalability of these techniques for large problems. We do not develop new sampling methods but instead describe a blocked Gibbs sampler which is sufficiently scalable to accomodate many interesting problems. The sampler we describe applies to a restricted subset of the Generalized Linear Mixed-effects Models (GLMM's); this subset includes Poisson and Gaussian regression models. The blocked Gibbs sampling steps jointly update a prior variance parameter along with all of the random effects underneath it. We also discuss extensions such as flexible prior distributions.},
  pubstate = {prepublished},
  version = {1},
  keywords = {FOS: Computer and information sciences,literatura,Methodology (stat.ME)}
}

@inproceedings{KarrasEtAl2022_DistributedGibbsSampling,
  title = {Distributed {{Gibbs Sampling}} and {{LDA Modelling}} for {{Large Scale Big Data Management}} on {{PySpark}}},
  booktitle = {2022 7th {{South-East Europe Design Automation}}, {{Computer Engineering}}, {{Computer Networks}} and {{Social Media Conference}} ({{SEEDA-CECNSM}})},
  author = {Karras, Christos and Karras, Aristeidis and Tsolis, Dimitrios and Giotopoulos, Konstantinos C. and Sioutas, Spyros},
  date = {2022-09-23},
  pages = {1--8},
  publisher = {IEEE},
  location = {Ioannina, Greece},
  doi = {10.1109/SEEDA-CECNSM57760.2022.9932990},
  url = {https://ieeexplore.ieee.org/document/9932990/},
  urldate = {2025-04-20},
  eventtitle = {2022 7th {{South-East Europe Design Automation}}, {{Computer Engineering}}, {{Computer Networks}} and {{Social Media Conference}} ({{SEEDA-CECNSM}})},
  isbn = {979-8-3503-9858-8},
  keywords = {literatura}
}

@article{KarunarasanEtAl2023_ComparisonBayesianMarkov,
  title = {A Comparison of {{Bayesian Markov}} Chain {{Monte Carlo}} Methods in a Multilevel Scenario},
  author = {Karunarasan, Darshika and Sooriyarachchi, Roshini and Pinto, Vimukthini},
  date = {2023-10-03},
  journaltitle = {Communications in Statistics - Simulation and Computation},
  shortjournal = {Communications in Statistics - Simulation and Computation},
  volume = {52},
  number = {10},
  pages = {4756--4772},
  issn = {0361-0918, 1532-4141},
  doi = {10.1080/03610918.2021.1967985},
  url = {https://www.tandfonline.com/doi/full/10.1080/03610918.2021.1967985},
  urldate = {2025-04-20},
  langid = {english},
  keywords = {literatura}
}

@article{Kim1998_StochasticVolatilityLH,
  title = {Stochastic Volatility: {{Likelihood}} Inference and Comparison with {{ARCH}} Models},
  author = {Kim, Sangjoon and Shephard, Neil and Chib, Siddhartha},
  date = {1998},
  journaltitle = {The Review of Economic Studies},
  volume = {65},
  number = {3},
  eprint = {2566931},
  eprinttype = {jstor},
  pages = {361--393},
  publisher = {[Oxford University Press, Review of Economic Studies, Ltd.]},
  issn = {00346527, 1467937X},
  url = {http://www.jstor.org/stable/2566931},
  urldate = {2025-04-07},
  abstract = {In this paper, Markov chain Monte Carlo sampling methods are exploited to provide a unified, practical likelihood-based framework for the analysis of stochastic volatility models. A highly effective method is developed that samples all the unobserved volatilities at once using an approximating offset mixture model, followed by an importance reweighting procedure. This approach is compared with several alternative methods using real data. The paper also develops simulation-based methods for filtering, likelihood evaluation and model failure diagnostics. The issue of model choice using non-nested likelihood ratios and Bayes factors is also investigated. These methods are used to compare the fit of stochastic volatility and GARCH models. All the procedures are illustrated in detail.},
  keywords = {literatura}
}

@book{Kruschke2015_DoingBayesianData,
  title = {Doing {{Bayesian}} Data Analysis: A Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  shorttitle = {Doing {{Bayesian}} Data Analysis},
  author = {Kruschke, John K.},
  date = {2015},
  edition = {Edition 2},
  publisher = {Academic Press},
  location = {Boston},
  abstract = {Provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data},
  isbn = {978-0-12-405888-0},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\ECVWJNFU\Kruschke - 2015 - Doing Bayesian data analysis a tutorial with R, J.pdf}
}

@book{LiangEtAl2010_AdvancedMarkovChain,
  title = {Advanced {{Markov Chain Monte Carlo Methods}}: {{Learning}} from {{Past Samples}}},
  shorttitle = {Advanced {{Markov Chain Monte Carlo Methods}}},
  author = {Liang, Faming and Liu, Chuanhai and Carroll, Raymond J.},
  date = {2010-07-16},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9780470669723},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9780470669723},
  urldate = {2025-04-18},
  isbn = {978-0-470-66972-3},
  langid = {english},
  keywords = {literatura}
}

@article{LuChen2022_BayesianAnalysisLongitudinal,
  title = {Bayesian Analysis of Longitudinal Binary Responses Based on the Multivariate Probit Model: {{A}} Comparison of Five Methods},
  shorttitle = {Bayesian Analysis of Longitudinal Binary Responses Based on the Multivariate Probit Model},
  author = {Lu, Kaifeng and Chen, Fang},
  date = {2022-12},
  journaltitle = {Statistical Methods in Medical Research},
  shortjournal = {Stat Methods Med Res},
  volume = {31},
  number = {12},
  pages = {2261--2286},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/09622802221122403},
  url = {https://journals.sagepub.com/doi/10.1177/09622802221122403},
  urldate = {2025-04-20},
  abstract = {Dichotomous response data observed over multiple time points, especially data that exhibit longitudinal structures, are important in many applied fields. The multivariate probit model has been an attractive tool in such situations for its ability to handle correlations among the outcomes, typically by modeling the covariance (correlation) structure of the latent variables. In addition, a multivariate probit model facilitates controlled imputations for nonignorable dropout, a phenomenon commonly observed in clinical trials of experimental drugs or biologic products. While the model is relatively simple to specify, estimation, particularly from a Bayesian perspective that relies on Markov chain Monte Carlo sampling, is not as straightforward. Here we compare five sampling algorithms for the correlation matrix and discuss their merits: a parameter-expanded Metropolis-Hastings algorithm (Zhang et al., 2006), a parameter-expanded Gibbs sampling algorithm (Talhouk et al., 2012), a parameter-expanded Gibbs sampling algorithm with unit constraints on conditional variances (Tang, 2018), a partial autocorrelation parameterization approach (Gaskins et al., 2014), and a semi-partial correlation parameterization approach (Ghosh et al., 2021). We describe each algorithm, use simulation studies to evaluate their performance, and focus on comparison criteria such as computational cost, convergence time, robustness, and ease of implementations. We find that the parameter-expanded Gibbs sampling algorithm by Talhouk et al. (2012) often has the most efficient convergence with relatively low computational complexity, while the partial autocorrelation parameterization approach is more flexible for estimating the correlation matrix of latent variables for typical late phase longitudinal studies.},
  langid = {english},
  keywords = {literatura}
}

@online{MahaniSharabiani2013_MetropolisHastingsSamplingUsing,
  title = {Metropolis-{{Hastings Sampling Using Multivariate Gaussian Tangents}}},
  author = {Mahani, Alireza S. and Sharabiani, Mansour T. A.},
  date = {2013},
  doi = {10.48550/ARXIV.1308.0657},
  url = {https://arxiv.org/abs/1308.0657},
  urldate = {2025-04-20},
  abstract = {We present MH-MGT, a multivariate technique for sampling from twice-differentiable, log-concave probability density functions. MH-MGT is Metropolis-Hastings sampling using asymmetric, multivariate Gaussian proposal functions constructed from Taylor-series expansion of the log-density function. The mean of the Gaussian proposal function represents the full Newton step, and thus MH-MGT is the stochastic counterpart to Newton optimization. Convergence analysis shows that MH-MGT is well suited for sampling from computationally-expensive log-densities with contributions from many independent observations. We apply the technique to Gibbs sampling analysis of a Hierarchical Bayesian marketing effectiveness model built for a large US foodservice distributor. Compared to univariate slice sampling, MH-MGT shows 6x improvement in sampling efficiency, measured in terms of `function evaluation equivalents per independent sample'. To facilitate wide applicability of MH-MGT to statistical models, we prove that log-concavity of a twice-differentiable distribution is invariant with respect to 'linear-projection' transformations including, but not restricted to, generalized linear models.},
  pubstate = {prepublished},
  version = {1},
  keywords = {65C05 65C60,FOS: Computer and information sciences,literatura,Methodology (stat.ME)}
}

@book{Marek2012_Pravdepodobnost,
  title = {Pravděpodobnost},
  author = {family=Marek, given=Luboš., given-i={{Luboš}}},
  date = {2012},
  edition = {1. vyd},
  publisher = {Professional Publishing},
  location = {Praha},
  isbn = {978-80-7431-087-4},
  langid = {czech},
  keywords = {literatura},
  annotation = {OCLC: 806200448}
}

@online{MbalawataEtAl2013_AdaptiveMetropolisAlgorithm,
  title = {Adaptive {{Metropolis Algorithm Using Variational Bayesian Adaptive Kalman Filter}}},
  author = {Mbalawata, Isambi S. and Särkkä, Simo and Vihola, Matti and Haario, Heikki},
  date = {2013},
  doi = {10.48550/ARXIV.1308.5875},
  url = {https://arxiv.org/abs/1308.5875},
  urldate = {2025-04-18},
  abstract = {Markov chain Monte Carlo (MCMC) methods are powerful computational tools for analysis of complex statistical problems. However, their computational efficiency is highly dependent on the chosen proposal distribution, which is generally difficult to find. One way to solve this problem is to use adaptive MCMC algorithms which automatically tune the statistics of a proposal distribution during the MCMC run. A new adaptive MCMC algorithm, called the variational Bayesian adaptive Metropolis (VBAM) algorithm, is developed. The VBAM algorithm updates the proposal covariance matrix using the variational Bayesian adaptive Kalman filter (VB-AKF). A strong law of large numbers for the VBAM algorithm is proven. The empirical convergence results for three simulated examples and for two real data examples are also provided.},
  pubstate = {prepublished},
  version = {3},
  keywords = {FOS: Mathematics,literatura,Statistics Theory (math.ST)}
}

@book{McElreath2020_StatisticalRethinkingBayesian,
  title = {Statistical Rethinking: A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical Rethinking},
  author = {McElreath, Richard},
  date = {2020},
  series = {Chapman \& {{Hall}}/{{CRC}} Texts in Statistical Science Series},
  edition = {Second edition},
  publisher = {CRC Press},
  location = {Boca Raton},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.},
  isbn = {978-0-367-13991-9},
  pagetotal = {593},
  keywords = {Bayes,Bayes Theorem,Bayes-Entscheidungstheorie,Bayesian statistical decision theory,Computer programs,Computer software,Data Interpretation Statistical,literatura,Logiciels,Mathematical Computing,Mathematics,R,R (Computer program language),R (Langage de programmation),software,Software,Statistisches Modell,Théorème de Bayes,Théorie de la décision bayésienne},
  annotation = {OCLC: on1130764237},
  file = {C:\Users\Michal\Zotero\storage\NWDHKDSR\McElreath - 2020 - Statistical rethinking a Bayesian course with exa.pdf}
}

@article{MetropolisEtAl1953_EquationStateCalculations,
  title = {Equation of {{State Calculations}} by {{Fast Computing Machines}}},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  date = {1953-06-01},
  journaltitle = {The Journal of Chemical Physics},
  volume = {21},
  number = {6},
  pages = {1087--1092},
  issn = {0021-9606, 1089-7690},
  doi = {10.1063/1.1699114},
  url = {https://pubs.aip.org/jcp/article/21/6/1087/202680/Equation-of-State-Calculations-by-Fast-Computing},
  urldate = {2025-04-18},
  abstract = {A general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. The method consists of a modified Monte Carlo integration over configuration space. Results for the two-dimensional rigid-sphere system have been obtained on the Los Alamos MANIAC and are presented here. These results are compared to the free volume equation of state and to a four-term virial coefficient expansion.},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\PW2U8HWR\Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing Machines.pdf}
}

@book{ShumwayStoffer2017_TimeSeriesAnalysis,
  title = {Time {{Series Analysis}} and {{Its Applications}}: {{With R Examples}}},
  shorttitle = {Time {{Series Analysis}} and {{Its Applications}}},
  author = {Shumway, Robert H. and Stoffer, David S.},
  date = {2017},
  series = {Springer {{Texts}} in {{Statistics}}},
  edition = {4th ed. 2017},
  publisher = {Springer},
  location = {Cham},
  doi = {10.1007/978-3-319-52452-8},
  isbn = {978-3-319-52452-8},
  langid = {english},
  pagetotal = {562},
  keywords = {literatura}
}

@book{Tsay2005_AnalysisFinancialTime,
  title = {Analysis of Financial Time Series},
  author = {Tsay, Ruey S.},
  date = {2005},
  edition = {2nd ed},
  publisher = {Wiley},
  location = {Hoboken, N.J},
  isbn = {978-0-471-69074-0},
  pagetotal = {605},
  keywords = {Econometrics,literatura,Risk management,Time-series analysis}
}

@book{Vickers2010_WhatPvalueAnyway,
  title = {What Is a {{P-value}} Anyway? 34 Stories to Help You Actually Understand Statistics},
  shorttitle = {What Is a {{P-value}} Anyway?},
  author = {Vickers, Andrew},
  date = {2010},
  publisher = {Addison-Wesley},
  location = {Boston},
  isbn = {978-0-321-62930-2},
  pagetotal = {212},
  keywords = {literatura,Mathematical statistics},
  annotation = {OCLC: ocn319602638}
}

@article{WassersteinEtAl2019_MovingWorld005,
  title = {Moving to a {{World Beyond}} “ {\mkbibemph{p}} {$<$} 0.05”},
  author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
  date = {2019-03-29},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {73},
  pages = {1--19},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2019.1583913},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2019.1583913},
  urldate = {2024-11-01},
  issue = {sup1},
  langid = {english},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\F62ZECYQ\Wasserstein et al. - 2019 - Moving to a World Beyond “ p  0.05”.pdf}
}

@book{Wooldridge2020_IntroductoryEconometricsModern,
  title = {Introductory Econometrics: A Modern Approach},
  shorttitle = {Introductory Econometrics},
  author = {Wooldridge, Jeffrey M.},
  date = {2020},
  edition = {Seventh edition},
  publisher = {Cengage},
  location = {Boston, MA},
  isbn = {978-1-337-55886-0},
  langid = {english},
  pagetotal = {826},
  keywords = {literatura},
  file = {C:\Users\Michal\Zotero\storage\ERC77IE6\Wooldridge - 2020 - Introductory econometrics a modern approach.pdf}
}

@online{ZhangEtAl2024_PathIntegralMonte,
  title = {Path Integral {{Monte Carlo}} in a Discrete Variable Representation with {{Gibbs}} Sampling: Dipolar Planar Rotor Chain},
  shorttitle = {Path Integral {{Monte Carlo}} in a Discrete Variable Representation with {{Gibbs}} Sampling},
  author = {Zhang, Wenxue and Moeed, Muhammad Shaeer and Bright, Andrew and Serwatka, Tobias and De Oliveira, Estevao and Roy, Pierre-Nicholas},
  date = {2024},
  doi = {10.48550/ARXIV.2410.13633},
  url = {https://arxiv.org/abs/2410.13633},
  urldate = {2025-04-20},
  abstract = {In this work, we propose a Path Integral Monte Carlo (PIMC) approach based on discretized continuous degrees of freedom and rejection-free Gibbs sampling. The ground state properties of a chain of planar rotors with dipole-dipole interactions are used to illustrate the approach. Energetic and structural properties are computed and compared to exact diagonalization and Numerical Matrix Multiplication for \$N \textbackslash leq 3\$ to assess the systematic Trotter factorization error convergence. For larger chains with up to N = 100 rotors, Density Matrix Renormalization Group (DMRG) calculations are used as a benchmark. We show that using Gibbs sampling is advantageous compared to traditional Metroplolis-Hastings rejection importance sampling. Indeed, Gibbs sampling leads to lower variance and correlation in the computed observables.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Atomic and Molecular Clusters (physics.atm-clus),Chemical Physics (physics.chem-ph),FOS: Physical sciences,literatura,Mesoscale and Nanoscale Physics (cond-mat.mes-hall),Quantum Physics (quant-ph),Statistical Mechanics (cond-mat.stat-mech)}
}
