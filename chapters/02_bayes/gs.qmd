One of the drawbacks of MA and MHA is the need to fine-tune the proposal distribution so that the samples can
efficiently explore the posterior distribution. If the proposal distribution rarely generates common values in the
posterior, the chains might not converge quickly \parencite[Chap. 7.4.4]{Kruschke2015_DoingBayesianData}.

The Gibbs sampler (GS) is a special case of MHA that cleverly sets the proposal distribution, which makes the chain
converge more quickly to the posterior distribution. The main idea arises from adaptive MHA, which tries to update the
proposal distribution slightly after some iterations, which might increase the efficiency. GS chooses proposal
distributions for each parameter individually instead of updating the proposal distribution or adjusting its step size.
The choice is based on a known conjugate posterior distribution for each parameter
\parencite[9.2.1]{McElreath2020_StatisticalRethinkingBayesian}. GS is often better in multidimensional models, where
the full posterior distribution is unknown. However, the conditional posteriors of individual parameters are known, and
values can be sampled from them \parencite[Chap. 11.1]{Gelman2014_BayesianDataAnalysis}. In cases where only some
marginal posterior densities are known, combining GS with MHA to sample from the posterior distribution efficiently is
possible. This method is known as the Metropolis-within-Gibbs sampler \parencite{Griffin2011OnAM}.

GS is especially useful in hierarchical models, where conditional probabilities naturally arise.
\parencite[Chap. 7.4.4]{Kruschke2015_DoingBayesianData} notes that GS is a special case of MHA. He compares both
algorithms to a MH random walk through the parameter space, where the next step depends only on the current step. While
MHA tries to create a step in every direction simultaneously, GS does one step in every direction sequentially. In a
multidimensional parameter space $\Theta = [\theta_1, \theta_2]$, MHA generates a new proposal from a proposal
multidimensional distribution, so

$$
\theta^* \sim N_2(\theta_{t-1}, \Sigma),
$$

where $\Sigma$ is a variance-covariance matrix that determines the shape of the proposal distribution. GS generates new
proposals conditionally on already accepted samples from conditional posterior distributions. Assuming known posterior
distributions $P(\theta_1 | \theta_2, x)$ for $\theta_1$ and $P(\theta_2 | \theta_1, x)$ for $\theta_2$, the sampler
uses them as proposal distributions. First, a new proposal for $\theta_1$ is generated, so

$$
\theta^*_1 \sim P(\theta_1 | \theta_{2, t-1}, x).
$$

After the new sample is either accepted or rejected, a new proposal for $\theta_2$ is generated, conditional on the new
$\theta_1$ sample, and

$$
\theta^*_2 \sim P(\theta_2 | \theta_{1, t-1}, x).
$$

While the proposal for $\theta_1$ is generated conditional on $\theta_{2, t-1}$, the proposal for $\theta_2$ is
conditional on the sample at time $t$, $\theta^{1, t}$, which allows the GS to more efficiently create sequential steps
in the posterior parameter space $\Theta$. The proposals may be accepted or rejected with a $\min(1, r)$ probability
specified in Equations @eq-ma or @eq-mha. However, \parencite[Chap. 11.3]{Gelman2014_BayesianDataAnalysis} proves that
the ratio $r$ always equals 1, and a new sample is always accepted. The acceptance-rejection criterion can be skipped,
improving the convergence speed as the ratio of two functions does not need to be computed.
\parencite[Chap. 11.1]{Gelman2014_BayesianDataAnalysis} describes this process in a general way for arbitrary
$k$-dimensional parameter space and provides a graphical comparison of both methods, as shown in Figure @fig-mha-gs.
The solid black dots represent the starting point of 5 independent chains used for this simulation. Axis $x$ represents
samples of arbitrary parameter $\theta_1$ and axis $y$ parameter $\theta_2$. Note that the figure combines Figures 11.1
and 11.2 from the source.

![Comparison of MHA and GS from \parencite{Gelman2014_BayesianDataAnalysis}](./img/mha-gs.png){#fig-mha-gs}

The left panel shows the convergence of MHA, where the step is taken in all directions at once. The right panel shows
convergence in steps, where a step in either a horizontal or vertical direction is taken one at a time.

The efficiency of GS has been reviewed in multiple publications. \parencite{LuChen2022_BayesianAnalysisLongitudinal}
found that a variation of Gibbs sampler is more effective in a multivariate probit model that deals with longitudinal
data than other forms of MHA. \parencite{KarrasEtAl2022_DistributedGibbsSampling} uses GS implemented in Python and
PySpark to efficiently sample from the posterior of a general Latent Dirichlet Allocation model. In quantum statistical
mechanics, variation of the GS offers smaller variance and autocorrelation compared to the traditional MHA approach
\parencite{ZhangEtAl2024_PathIntegralMonte}.

Compared to a more flexible MHA, its main drawback is that the conditional distributions need to be known. If the model
does not offer conjugate combinations, MHA is more suitable. \parencite{KarunarasanEtAl2023_ComparisonBayesianMarkov}
explores this and finds that MHA is superior in some small cases where the conjugate is unknown and computer
numerically. However, they are not able to conclude that MHA is, in general, superior to GS in abstract multilevel
modeling. There are also advanced implementations of MHA that significantly outperform a simple GS.
\parencite{MahaniSharabiani2013_MetropolisHastingsSamplingUsing} develops a multivariate technique that leverages MHA
that offers *\enquote{6x improvement in sampling efficiency compared to univariate Gibbs}*. The authors argue that this
might be because, in high-dimensional spaces, GS needs to work with complex, high-dimensional conditional probability
functions that might be hard to compute.

There are also different implementations of GS. \parencite{HeEtAl2016_ScanOrderGibbs} define two common ways to sample
new values. Systematic scan iterates in a predefined cycle of parameters and generates them individually. This means
that $\theta_i$ is dependent on $\theta{j, t}$ for $j = 1, \dots, k - 1$ and $\theta_j^{t-1}$ for $j = k + 1, \dots, d$
where $d$ is the dimension of the model. Random scan selects a random parameter at iteration $t$ and samples from a
probability distribution conditioned on other latest samples. Selection is done until all parameters have a new sample
for iteration $t$. \parencite{JohnsonEtAl2016_ScalableBlockedGibbs} describes blocked GS that updates correlated
parameters jointly. Sampling blocks can be useful in Bayesian linear regression or Bayesian generalized linear
mixed-effects models.
