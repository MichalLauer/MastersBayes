To describe posterior distribution that is analytically unknown, bayesian statistics often use a method called Markov
Chain Monte Carlo (MCMC) sampling. \parencite[Chap. 11]{Gelman2014_BayesianDataAnalysis} describes MCMC as *\enquote{a
general method based on drawing values of $\theta$ from approximate distributions and then correcting those draws to
better approximate the target posterior distribution}*. In statistics, Monte Carlo simulations sample data from a known
population distribution, given some input parameters. Simulations allow researchers to compare different methods in the
same environment and get insight into what methods might be better in what conditions. Monte Carlo simulations can also
be used to estimate the bias, overconfidence, or statistical errors that will be expected when using such methods on
samples from the real world. It can measure the precision of point estimates or the expected width of confidence
intervals \parencite{HopkinsEtAl2024_HowWeKnow}. Monte Carlo chains are *\enquote{assessing the properties of a target
distribution by generating representative random values.}* \parencite[Chap. 7.4.5]{Kruschke2015_DoingBayesianData}. The
analytical form of the posterior distribution is often unknown, and using a simple Monte Carlo sampling technique is
insufficient to examine its properties.

Markov Chain is a stochastic process that describes the probability of moving into a different state. The probability
of transitioning into a different state at time $t+1$ is described by a transition matrix $T$ and is dependent only on
the current state $t$. Formally put, the probability that parameter $\theta$ transitions to state $A$ is

$$
P(\theta_{[t+1]} \in A | \theta_{[0]}, \theta_{[1]}, \dots, \theta_{[t-1]}, \theta_{[t]}) =
P(\theta_{[t+1]} \in A | \theta_{[t]}).
$$

Such a process has important properties that make it suitable for posterior sampling. Chains can explore the whole
space of possible values and move between low-density and high-density regions. If the chain is stationary[^mc-stan],
it will converge to a stationary distribution independently of the initial state. Translating these properties into
Bayesian sampling, properly defined stationary Markov Chains can explore the whole posterior distribution without
analytical expression \parencite[Chap. 6.8]{Hebak2013_StatistickeMysleniNastroje}. MCMC is a combination of Markov
Chain samples used to describe the true posterior distribution. On these samples, it is possible to compute properties
of the posterior distribution, such as the expected value, median, mode, or any interval metric.

[^mc-stan]: Stationarity in Markov Chains differs from stationarity in Time series.

Several methods use the MCMC methodology. The most popular methods are the Metropolis-Hastings algorithm, The
Metropolis Algorithm and the Gibbs Sampler are later explored in this thesis. Although MCMC sampling is guaranteed to
converge to the posterior distribution, full convergence is the limit of an infinitely long chain. Chains with finite
length can describe the posterior distribution with arbitrary precision. It is important to correctly define the MCMC
simulation and monitor the quality of convergence. \parencite[Chap. 7.5]{Kruschke2015_DoingBayesianData} defines three
main goals when samples are generated using MCMC methods:

1) representativeness,
2) accuracy and stability, and
3) efficiency.

Representativeness of a Markov Chain implies that the posterior distribution is explored fully and that the resulting
chains are not affected by the initial starting points. The accuracy of a chain is crucial in determining point
estimates, interval estimates, or when the distribution's tails are explored. Running the chain multiple times should
also give similar[^mc-similar] results that should be stable. Estimating the posterior should also not take a very long
time[^mc-long-time], and the samplers should be efficient.

[^mc-similar]: The results will never be the same because the chains are always affected by finite sample size.

[^mc-long-time]: This is dependent on the task at hand, and a \enquote{very long time} means something different in a
Bayesian linear regression, bayesian hierarchical model, estimation of state-space models, or casual DAG simulation.

The quality of chains is very important and is explored in several books, such as
\parencite{Kruschke2015_DoingBayesianData} or \parencite{Gelman2014_BayesianDataAnalysis}, or papers that aim to
optimize the bayesian workflow \parencite{GelmanEtAl2020_BayesianWorkflow}. The estimated parameters should not change
very much after the chain has stabilized. Plotting some central tendency of the estimated parameter against the
iteration can be a simple visual check of whether the estimate has stabilized. Charts can be further improved by
generating multiple chains and observing whether all chains converge to the same value. Similarly, plotting histograms
of the estimated parameters from multiple chains should show high overlap. The difference between chains can also be
measured with a shrink factor, representing variance between individual chains. The ideal shrink factor should be very
close to 1. Some authors suggest that a value greater than 1.1 implies instability, and the simulation should be
reviewed \parencite[Chap. 7.5.1]{Kruschke2015_DoingBayesianData}. These steps validate stability and accuracy but can
all fail if the resulting stable chains are inaccurate.

To measure the accuracy of the created chain, it is appropriate to look at the autocorrelation of generated samples. If
the autocorrelation is high, newly generated samples are not independent of historical states, and the chain can get
\enquote{stuck} in a particular place. High autocorrelation means that the chain needs to be very long to explore the
whole parameter space and get accurate estimates. This is often an issue for complex models which have high-dimensional
parameter space. If a chain exhibits high autocorrelation, there are at least two ways to correct this. The first is to
discard every $k$-th sample, which reduces the number of times the chain explores a specific region. While this can
help with accuracy, the computer still needs to generate all samples before removing some. Thinning reduces the
efficiency of sampler time to convergence and requires a larger number of computational power. That is why it is often
better to redefine the model more efficiently or use a sampler/tool built for such complexity.

The accuracy of the chain can also be measured using Effective Sample Size (ESS), which measures the true sample size
that the chain represents. The closer the ESS is to the number of samples that have been generated, the better the
accuracy of chains there is. It is often computed using the autocorrelation function so the results of autocorrelation
analysis and interpretation of ESS should give a similar conclusion. The quality of chains is often heavily influenced
by the first generated samples, which can be imprecise and very far from the stationary distribution. That is why the
first couple of samples are discarded in a burn-in period. Removing them increases the stability of the chain and their
accuracy.
